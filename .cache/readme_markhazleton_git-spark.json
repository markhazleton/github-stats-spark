{
  "timestamp": "2026-01-02T11:11:10.837507",
  "value": "<div align=\"center\">\n\n# \ud83d\udd25 Git Spark\n\n### Git Repository Analytics & Reporting\n\n**Analyze commit patterns and contributor activity with interactive reports**\n\n[![npm version](https://img.shields.io/npm/v/git-spark.svg?style=flat-square)](https://www.npmjs.com/package/git-spark)\n[![npm downloads](https://img.shields.io/npm/dm/git-spark.svg?style=flat-square)](https://www.npmjs.com/package/git-spark)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](https://opensource.org/licenses/MIT)\n[![Node.js Version](https://img.shields.io/badge/node-%3E%3D20.6.0-brightgreen?style=flat-square)](https://nodejs.org)\n[![GitHub issues](https://img.shields.io/github/issues/MarkHazleton/git-spark.svg?style=flat-square)](https://github.com/MarkHazleton/git-spark/issues)\n[![GitHub stars](https://img.shields.io/github/stars/MarkHazleton/git-spark.svg?style=flat-square)](https://github.com/MarkHazleton/git-spark/stargazers)\n\n**[\ud83c\udfa8 Live Demo](https://markhazleton.github.io/git-spark/)** \u2022\n**[\ud83d\udcd6 Documentation](#-documentation)** \u2022\n**[\ud83d\ude80 Quick Start](#-quick-start)**\n\n---\n\n</div>\n\n## \ud83d\udcca What is Git Spark?\n\nGit Spark analyzes Git repository commit history to provide insights into contributor activity, code changes, and development patterns. It generates interactive HTML reports with charts, contributor statistics, and file analysis based on Git commit data.\n\n### \u2728 Key Features\n\n- **Interactive Reports** - HTML dashboards with charts and activity visualizations\n- **Multiple Formats** - Export to HTML, JSON, CSV, and Markdown\n- **CLI & API** - Command-line tool and Node.js library\n- **File Analysis** - Directory structure and change patterns\n- **Git-only Data** - Analysis based solely on commit history\n\n## \ud83c\udfa8 Live Demo\n\n**[\ud83d\udcca View Interactive Demo \u2192](https://markhazleton.github.io/git-spark/)**\n\nSee Git Spark in action with a sample report showing:\n\n- Interactive charts and visualizations\n- Contributor activity and statistics  \n- File and directory analysis\n- Dark mode support\n- Data export options\n\n## \u2728 Features\n\n### \ud83d\udcca Analytics & Reports\n\n- **Repository Statistics** - Commit counts, contributor activity, and file changes\n- **Daily Trends** - Activity patterns over time with visual charts\n- **Contributor Analysis** - Individual contributor statistics and activity\n- **File Analysis** - Directory structure, file types, and change patterns\n- **Interactive HTML** - Charts, tables, and dark mode support\n\n### \ufffd\ufe0f Usage Options\n\n- **Command Line** - Simple CLI commands with progress indicators\n- **Node.js API** - Programmatic access for custom integrations\n- **Multiple Formats** - HTML, JSON, CSV, and Markdown output\n- **Configuration** - Customizable analysis periods and options\n\n### \ud83d\udda5\ufe0f Interactive HTML Report (v1.0)\n\nEnterprise-focused, accessible, and secure analytics dashboard:\n\n- **Multi\u2011Series Timeline** \u2013 Commits, churn (lines changed), and active authors with dataset toggles\n- **Daily Activity Trends** \u2013 Comprehensive daily analysis showing all days in the specified range with activity summaries\n- **GitHub-style Contributions Calendar** \u2013 Visual activity heatmap with color-coded intensity levels and interactive tooltips\n- **Risk Factors Bar Chart** \u2013 Visual breakdown of churn, recency, ownership, coupling potential, and knowledge concentration inputs\n- **Governance Radar Chart** \u2013 Conventional commit adherence, traceability, message quality, WIP/revert penalties\n- **Dark Mode Toggle (Persistent)** \u2013 Remembers preference via localStorage; charts dynamically re-theme\n- **One\u2011Click Data Export** \u2013 Download embedded JSON or CSV bundles directly from the report (offline capable)\n- **Progressive Table Pagination** \u2013 \u201cShow more\u201d incremental reveal for large author/file sets (performance friendly)\n- **Dataset Toggles & Live Updates** \u2013 Enable/disable series without reloading page\n- **Open Graph Preview Image** \u2013 Auto\u2011generated SVG summary for social sharing & link unfurling\n- **Accessibility Enhancements** \u2013 ARIA live region announcements for sorting; keyboard focus management; reduced\u2011motion compliance\n- **Security\u2011First Delivery** \u2013 Strict CSP with SHA\u2011256 hashed inline script & style blocks (no `unsafe-inline`), native SVG charts (no external chart library), fully self-contained reports\n- **Email Redaction Option** \u2013 Controlled via CLI flag (`--redact-emails`) for privacy sensitive audits\n- **Transparent Metrics Documentation** \u2013 Every team metric includes comprehensive limitations and data source explanations\n\n> **Analytical Integrity**: All analytics data are embedded (no external calls) ensuring the report is a self-contained artifact suitable for air\u2011gapped review workflows. Every metric includes honest explanations of what Git data can and cannot reveal.\n\n## \ud83d\ude80 Quick Start\n\n### Installation\n\n```bash\n# Global installation for CLI usage\nnpm install -g git-spark\n\n# Local installation for programmatic usage\nnpm install git-spark\n```\n\n### Basic Usage\n\n```bash\n# Analyze current repository (last 30 days)\ngit-spark --days=30\n\n# Generate HTML report\ngit-spark --format=html --output=./reports\n\n# Analyze specific date range\ngit-spark --since=2025-01-01 --until=2025-12-31\n```\n\n### Programmatic Usage\n\n```typescript\nimport { GitSpark, analyze } from 'git-spark';\n\n// Quick analysis\nconst report = await analyze('/path/to/repo', { days: 30 });\n\n// Advanced usage with options\nconst gitSpark = new GitSpark({\n  repoPath: '/path/to/repo',\n  since: '2025-01-01',\n  format: 'html',\n  output: './reports'\n});\n\nconst report = await gitSpark.analyze();\nawait gitSpark.export('html', './reports');\n```\n\n## \ud83d\udcd6 Documentation\n\n### CLI Commands\n\n#### `git-spark [options]`\n\nMain analysis command with comprehensive options:\n\n```bash\ngit-spark [options]\n\nOptions:\n  -d, --days <number>        analyze last N days\n  -s, --since <date>         start date (YYYY-MM-DD)\n  -u, --until <date>         end date (YYYY-MM-DD)\n  -f, --format <format>      output format (html|json|console|markdown|csv)\n  -o, --output <path>        output directory (default: \"./reports\")\n  -c, --config <path>        configuration file\n  -b, --branch <name>        analyze specific branch\n  -a, --author <name>        filter by author\n  -p, --path <glob>          filter by file path pattern\n  --heavy                    enable expensive analyses\n  --log-level <level>        logging verbosity (error|warn|info|debug|verbose)\n  --no-cache                 disable caching\n  --redact-emails            redact email addresses in reports\n  --exclude-extensions <ext> comma-separated list of file extensions to exclude (e.g., .md,.txt)\n  --azure-devops             enable Azure DevOps pull request analytics\n  --devops-org <org>         Azure DevOps organization name\n  --devops-project <project> Azure DevOps project name\n  --devops-repo <repo>       Azure DevOps repository (auto-detected if not specified)\n  --devops-token <token>     Azure DevOps Personal Access Token\n  -h, --help                 display help for command\n```\n\n#### `git-spark analyze`\n\nDetailed analysis with additional options:\n\n```bash\ngit-spark analyze [options]\n\nOptions:\n  -r, --repo <path>          repository path (default: current directory)\n  [all main command options]\n```\n\n#### `git-spark health`\n\nQuick repository health assessment:\n\n```bash\ngit-spark health [options]\n\nOptions:\n  -r, --repo <path>          repository path (default: current directory)\n```\n\n#### `git-spark html`\n\nGenerate comprehensive HTML report with additional options:\n\n```bash\ngit-spark html [options]\n\nOptions:\n  -r, --repo <path>          repository path (default: current directory)\n  -d, --days <number>        analyze last N days\n  -s, --since <date>         start date (YYYY-MM-DD)\n  -u, --until <date>         end date (YYYY-MM-DD)\n  -o, --output <path>        output directory (default: \"./reports\")\n  -b, --branch <name>        analyze specific branch\n  -a, --author <name>        filter by author\n  -p, --path <glob>          filter by file path pattern\n  --open                     open HTML report in browser after generation\n  --serve                    start HTTP server to serve the report\n  --port <number>            port for HTTP server (default: 3000)\n  --heavy                    enable expensive analyses for detailed insights\n```\n\nExamples:\n\n```bash\n# Generate HTML report for last 30 days\ngit-spark html --days=30\n\n# Generate and open in browser\ngit-spark html --days=30 --open\n\n# Generate and serve on local web server\ngit-spark html --days=60 --serve --port=8080\n\n# Heavy analysis with detailed insights\ngit-spark html --days=90 --heavy --output=./detailed-reports\n\n# With Azure DevOps pull request analytics\ngit-spark html --days=30 --azure-devops --devops-org=myorg --devops-project=myproject\n```\n\n### Azure DevOps Integration\n\nGit Spark includes optional Azure DevOps integration for comprehensive pull request analytics alongside Git commit analysis.\n\n#### Setup\n\n1. **Create a Personal Access Token (PAT)** in Azure DevOps with 'Code (Read)' scope\n2. **Set environment variable** or pass token via CLI:\n\n   ```bash\n   export AZURE_DEVOPS_TOKEN=your-pat-token\n   # or\n   git-spark --azure-devops --devops-token=your-pat-token\n   ```\n\n#### Usage Examples\n\n```bash\n# Auto-detect organization, project, and repo from Git remote\ngit-spark --azure-devops --days=30\n\n# Specify Azure DevOps details explicitly\ngit-spark --azure-devops --devops-org=myorg --devops-project=myproject --devops-repo=myrepo\n\n# Generate HTML report with PR analytics\ngit-spark html --azure-devops --days=60 --output=./reports\n\n# Use token from environment variable\nexport AZURE_DEVOPS_TOKEN=your-pat-token\ngit-spark --azure-devops --days=30\n```\n\n#### Features\n\n- **Pull Request Analytics**: Comprehensive PR workflow analysis including cycle times, review metrics\n- **Work Item Tracking**: Link PRs to work items and requirements\n- **Review Metrics**: Review efficiency and collaboration patterns\n- **Intelligent Caching**: Multi-level caching reduces API calls and respects rate limits\n- **Graceful Degradation**: Continues Git analysis if Azure DevOps is unavailable\n- **Automatic Configuration**: Auto-detects Azure DevOps settings from Git remotes\n\n#### Configuration\n\nAdd Azure DevOps settings to `.git-spark.json`:\n\n```json\n{\n  \"azureDevOps\": {\n    \"enabled\": true,\n    \"organization\": \"myorg\",\n    \"project\": \"myproject\",\n    \"repository\": \"myrepo\",\n    \"auth\": {\n      \"method\": \"pat\",\n      \"tokenEnvVar\": \"AZURE_DEVOPS_TOKEN\"\n    },\n    \"cache\": {\n      \"enabled\": true,\n      \"ttlMinutes\": 60\n    }\n  }\n}\n```\n\n#### `git-spark validate`\n\nEnvironment and requirements validation:\n\n```bash\ngit-spark validate\n```\n\n#### Daily Trends Analysis Examples\n\n```bash\n# Analyze last 7 days with comprehensive daily trends\ngit-spark --days=7 --format=html\n\n# Extended 60-day analysis with contributions calendar\ngit-spark --days=60 --format=html --output=./reports\n\n# Generate JSON with complete daily trends data for external processing\ngit-spark --days=30 --format=json --output=./data\n\n# Heavy analysis with all features including detailed daily patterns\ngit-spark --days=30 --heavy --format=html\n```\n\n#### File Exclusion Examples\n\n```bash\n# Exclude markdown files from analysis\ngit-spark --days=30 --exclude-extensions=.md\n\n# Exclude multiple file types\ngit-spark --days=30 --exclude-extensions=.md,.txt,.log\n\n# Exclude documentation files for code-focused analysis\ngit-spark html --days=60 --exclude-extensions=.md,.rst,.adoc\n\n# Combine with other filters\ngit-spark --days=30 --exclude-extensions=.md --branch=main --author=john@example.com\n```\n\n### Configuration\n\nCreate a `.git-spark.json` configuration file to customize analysis:\n\n> **Note**: Configuration file support is available for basic analysis options. The configuration system supports custom thresholds, weights, and exclusion patterns for fine-tuned analysis.\n\n```json\n{\n  \"version\": \"1.0\",\n  \"analysis\": {\n    \"excludePaths\": [\n      \"node_modules/**\",\n      \"dist/**\",\n      \"build/**\",\n      \".git/**\"\n    ],\n    \"excludeExtensions\": [\n      \".md\",\n      \".txt\"\n    ],\n    \"excludeAuthors\": [\n      \"dependabot[bot]\",\n      \"github-actions[bot]\"\n    ],\n    \"thresholds\": {\n      \"largeCommitLines\": 500,\n      \"smallCommitLines\": 50,\n      \"staleBranchDays\": 30,\n      \"largeFileKB\": 300,\n      \"hotspotAuthorThreshold\": 3\n    },\n    \"weights\": {\n      \"risk\": {\n        \"churn\": 0.35,\n        \"recency\": 0.25,\n        \"ownership\": 0.20,\n        \"entropy\": 0.10,\n        \"coupling\": 0.10\n      }\n    }\n  },\n  \"output\": {\n    \"defaultFormat\": \"html\",\n    \"outputDir\": \"./reports\",\n    \"redactEmails\": false\n  },\n  \"performance\": {\n    \"maxBuffer\": 200,\n    \"enableCaching\": true,\n    \"cacheDir\": \".git-spark-cache\",\n    \"chunkSize\": 1000\n  }\n}\n```\n\n### API Reference\n\n#### `GitSpark` Class\n\n```typescript\nclass GitSpark {\n  constructor(options: GitSparkOptions, progressCallback?: ProgressCallback)\n  \n  async analyze(): Promise<AnalysisReport>\n  async export(format: OutputFormat, outputPath: string): Promise<void>\n  \n  static getDefaultConfig(): GitSparkConfig\n}\n```\n\n#### `GitSparkOptions` Interface\n\n```typescript\ninterface GitSparkOptions {\n  repoPath?: string;           // Repository path\n  since?: string;              // Start date (YYYY-MM-DD)\n  until?: string;              // End date (YYYY-MM-DD)\n  days?: number;               // Last N days\n  branch?: string;             // Specific branch\n  author?: string;             // Author filter\n  path?: string;               // Path filter\n  format?: OutputFormat;       // Output format\n  output?: string;             // Output directory\n  config?: string;             // Config file path\n  heavy?: boolean;             // Enable expensive analyses\n  logLevel?: LogLevel;         // Log level\n  noCache?: boolean;           // Disable caching\n}\n```\n\n#### Quick Functions\n\n```typescript\n// Quick analysis function\nasync function analyze(\n  repoPath?: string, \n  options?: Partial<GitSparkOptions>\n): Promise<AnalysisReport>\n\n// Quick export function\nasync function exportReport(\n  report: AnalysisReport,\n  format: OutputFormat,\n  outputPath: string\n): Promise<void>\n```\n\n## \ufffd Analytical Integrity & Data Limitations\n\n### Our Commitment to Honest Analytics\n\nGit Spark is built on a foundation of **complete transparency** about what can and cannot be determined from Git repository data alone. We never guess, estimate, or fabricate metrics from unavailable data sources.\n\n### What Git Data CAN Provide\n\n\u2705 **Commit metadata**: Author, committer, timestamp, message  \n\u2705 **File changes**: Additions, deletions, modifications  \n\u2705 **Branch and merge history**: Repository structure and workflow patterns  \n\u2705 **Temporal patterns**: When changes occurred based on commit timing  \n\u2705 **Contribution patterns**: Who worked on what files and when  \n\n### What Git Data CANNOT Provide\n\n\u274c **Code review data**: No reviewer information, approval status, or review comments  \n\u274c **Pull/merge request metadata**: No PR numbers, descriptions, or review workflows  \n\u274c **Issue tracking**: No bug reports, feature requests, or issue relationships  \n\u274c **Deployment information**: No production deployments, rollbacks, or environment data  \n\u274c **Team structure**: No organizational hierarchy, roles, or responsibilities  \n\u274c **Work hours/timezone**: No actual working hours, vacation schedules, or availability  \n\u274c **Performance metrics**: No build times, test results, or runtime performance  \n\n### Our Honest Metric Approach\n\n- **Transparent Naming**: Metric names clearly indicate data source limitations\n- **Comprehensive Documentation**: Every metric includes limitation warnings\n- **Platform Detection**: We identify hosting platforms but acknowledge Git data is fundamentally the same\n- **Educational Focus**: We help users understand what metrics do and don't measure\n- **No False Claims**: We never imply Git data provides complete team performance insights\n\n### User Education & Responsible Usage\n\nAll team-related metrics include detailed explanations of:\n\n- What the metric actually measures from Git data\n- Known limitations and potential misinterpretations  \n- Recommended approaches for supplementing Git analytics\n- Warnings against using metrics for performance reviews without context\n\n## \ufffd\ud83d\udcca Report Formats\n\n### HTML Reports\n\nInteractive reports with transparent analytics and comprehensive limitations documentation:\n\n- **Executive Summary** - Health rating with activity index breakdown and clear data source explanations\n- **Limitations Section** - Comprehensive documentation of what Git data can and cannot reveal (positioned before detailed metrics)\n- **Top Contributors** - Author metrics table with detailed activity patterns\n- **Team Activity Patterns** - Aggregate repository metrics showing overall activity distribution\n- **File Activity Hotspots** - Source code files with highest activity (filtered for relevant code files)\n- **Author Activity Details** - Detailed profile cards for each contributor with commit patterns, file focus, and insights\n- **Daily Activity Trends** - Comprehensive day-by-day analysis with GitHub-style contributions calendar (optional)\n- **Calculation Documentation** - Transparent methodology for all metrics including formulas and measurement principles\n- **Report Metadata** - Generation details, Git branch information, and processing statistics\n- Interactive visualizations with dark mode support\n- Progressive table pagination for performance\n- Sortable columns with accessibility features\n- Export capabilities for downstream analysis\n- CSP/SRI security hardening\n\n> **Transparency First**: Every metric in the HTML report includes clear explanations of what it measures, its data sources, and its limitations. The limitations section is prominently positioned before detailed calculations to ensure users understand data constraints upfront.\n\n### JSON Reports\n\nMachine-readable format for:\n\n- CI/CD integration\n- Custom tooling integration\n- Data processing and analysis\n- API consumption\n\n### Console Output\n\nTerminal-friendly format with:\n\n- Color-coded health indicators\n- Tabular data presentation\n- Progress indicators\n- Quick insights and recommendations\n\n### Markdown Reports\n\nDocumentation-friendly format for:\n\n- README integration\n- Wiki documentation\n- Version control tracking\n- Collaboration and sharing\n\n### CSV Exports\n\nSpreadsheet-compatible format with separate files for:\n\n- `authors.csv` - Author statistics and metrics\n- `files.csv` - File-level analysis and risk scores\n- `timeline.csv` - Daily activity and trends (includes all days in analysis period)\n\n## \ud83d\udd0d Analysis Details\n\n### Repository Health Score\n\nComposite metric based on:\n\n- **Commit Frequency** - Regular development activity\n- **Author Diversity** - Distributed knowledge and contributions\n- **Commit Size Distribution** - Balanced change patterns\n- **Governance Adherence** - Code quality and standards compliance\n\n### Daily Activity Trends\n\nComprehensive daily analysis providing:\n\n- **Complete Date Range Coverage** - Shows all days in the specified period, including days with zero activity\n- **Activity Metrics** - Commits, authors, file changes, and code volume per day\n- **GitHub-style Contributions Calendar** - Visual heatmap with intensity levels (0-4) matching GitHub's color scheme\n- **Interactive Tooltips** - Hover to see exact commit counts and dates\n- **Week-based Organization** - Calendar view organized by weeks for easy pattern recognition\n- **JSON Export Support** - All daily trends data available for external processing and analysis\n\n> **Enhanced Coverage**: Unlike traditional analytics that only show active days, Git Spark's daily trends include every day in your analysis period, providing complete visibility into work patterns and identifying both active and quiet periods.\n\n### Risk Analysis\n\nFile-level risk assessment (activity scoring) considering:\n\n- **Code Churn** - Frequency and volume of changes\n- **Author Count** - Number of different contributors\n- **Recency** - How recently files were modified\n- **Ownership Distribution** - Knowledge concentration across files\n\nRisk metrics help identify files that may need attention due to high activity levels, but do not indicate code quality or defect likelihood.\n\n### Team Analytics\n\nTeam organization and specialization insights covering:\n\n- **Developer Specialization** - Measures how unique each developer's file set is compared to others, promoting clear areas of responsibility\n- **File Ownership Clarity** - Percentage of files with single-author ownership, indicating clear responsibility boundaries  \n- **Organization Efficiency** - Low file overlap between developers, suggesting better task distribution and reduced conflicts\n- **Commit Time Patterns** - Work timing analysis based on commit timestamps (not actual working hours)\n- **Team Active Coverage** - Days with multiple contributors (estimated pattern, not actual vacation coverage)\n\n> **\u26a0\ufe0f Important Approach**: The Team Organization Score measures specialization and clear ownership rather than traditional collaboration. High scores indicate well-organized teams with distinct areas of responsibility, which typically reduces conflicts and improves efficiency. Very high scores may sometimes indicate knowledge silos, while very low scores suggest unclear ownership or coordination issues. All metrics include comprehensive limitation documentation to prevent misinterpretation.\n\n## \ud83c\udfd7\ufe0f CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Repository Analysis\non: [push, pull_request]\n\njobs:\n  analyze:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0  # Full history for analysis\n      \n      - uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n      \n      - name: Install git-spark\n        run: npm install -g git-spark\n      \n      - name: Run analysis\n        run: git-spark --format=json --output=./reports\n      \n      - name: Upload reports\n        uses: actions/upload-artifact@v3\n        with:\n          name: git-spark-reports\n          path: ./reports/\n```\n\n### GitLab CI\n\n```yaml\nrepository_analysis:\n  stage: analysis\n  image: node:18\n  script:\n    - npm install -g git-spark\n    - git-spark --format=json --output=./reports\n  artifacts:\n    paths:\n      - reports/\n    expire_in: 1 week\n  only:\n    - main\n    - develop\n```\n\n## \ud83d\udd12 Security Considerations\n\nGit Spark is designed with security in mind:\n\n- **Input Validation** - All user inputs are validated and sanitized\n- **Path Traversal Protection** - Safe file path handling\n- **Email Redaction** - Optional email address anonymization\n- **Buffer Limits** - Configurable limits to prevent DoS attacks\n- **No Arbitrary Execution** - Git commands are parameterized and safe\n- **Dependency Security** - Minimal dependencies with security auditing\n- **Strict Content Security Policy** - Inline script & style blocks hashed (SHA\u2011256); no `unsafe-inline` or dynamic eval\n- **Native SVG Charts** - Self-contained visualizations with no external dependencies\n- **Single External Origin** - Minimizes supply chain surface\n- **Escaped Dynamic Content** - All user / repo derived strings safely encoded in HTML output\n\n**Security Reporting:** Please review our [Security Policy](SECURITY.md) for information on reporting vulnerabilities and our security practices.\n\n## \ud83c\udfaf Performance\n\nOptimized for large repositories:\n\n- **Streaming Processing** - Handle massive repositories without memory issues\n- **Intelligent Caching** - Avoid redundant Git operations\n- **Chunked Analysis** - Process commits in configurable batches\n- **Memory Management** - Efficient data structures and garbage collection\n- **Progress Tracking** - Real-time progress indicators for long operations\n\n**Benchmarks:**\n\n- 10k commits: ~10 seconds\n- 100k commits: ~2 minutes\n- Memory usage: <500MB for 100k commits\n\n**\ud83d\udcd6 For detailed performance optimization strategies, see the [Performance Tuning Guide](docs/performance-tuning.md)**\n\n## \ud83e\uddea Testing\n\n```bash\n# Run all tests\nnpm test\n\n# Run with coverage\nnpm run test:coverage\n\n# Run specific test suite\nnpm test -- --testNamePattern=\"GitSpark\"\n\n# Run integration tests\nnpm run test:integration\n```\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions! Please see our [GitHub Issues](https://github.com/MarkHazleton/git-spark/issues) to get started or open a new issue to discuss your ideas.\n\n### Development Setup\n\n```bash\n# Clone repository\ngit clone https://github.com/MarkHazleton/git-spark.git\ncd git-spark\n\n# Install dependencies\nnpm install\n\n# Build TypeScript\nnpm run build\n\n# Run tests\nnpm test\n\n# Start development mode\nnpm run dev\n```\n\n### Code Standards\n\n- **TypeScript** - Full type safety and modern JavaScript features\n- **ESLint + Prettier** - Consistent code formatting and quality\n- **Jest Testing** - Comprehensive test coverage (>80%)\n- **Semantic Versioning** - Clear version management\n- **Conventional Commits** - Structured commit messages\n\n## \ud83d\udccb Roadmap\n\n### \u2705 Completed (v1.0)\n\n- **Core Analytics Engine** - Comprehensive Git repository analysis\n- **Multiple Output Formats** - HTML, JSON, Markdown, CSV, and console formats\n- **Transparent Team Metrics** - Honest metric terminology with comprehensive limitations documentation\n- **Analytical Integrity Framework** - Clear separation between what Git data can and cannot provide\n- **Enhanced User Education** - Comprehensive warnings and guidance about metric interpretation\n- **Daily Activity Trends** - Comprehensive daily analysis showing all days in specified range (including zero-activity days)\n- **GitHub-style Contributions Calendar** - Interactive activity heatmap with color-coded intensity levels and tooltips\n- **Activity Index Calculation** - Transparent breakdown of commit frequency, author participation, and consistency components\n- **Author Profile Cards** - Detailed individual contributor analysis with commit patterns and file focus\n- **Secure HTML Reports** - Strict CSP + SHA-256 hashed inline content (no unsafe-inline)\n- **Dark Mode** - Persistent theme preference with adaptive styling\n- **Progressive Tables** - Pagination & performance safeguards for large datasets\n- **Sortable Data Tables** - Column sorting with ARIA live announcements\n- **Accessibility Features** - ARIA live regions, keyboard navigation, reduced motion support\n- **OG Image Generation** - Auto-generated SVG summaries for social/link previews\n- **Email Redaction** - Privacy-focused email anonymization option\n- **CLI Commands** - Main analysis, health check, validation, and dedicated HTML report generation\n- **HTTP Server** - Built-in web server for local report viewing (`--serve` option)\n- **Auto-Open Browser** - Automatic browser launch after report generation (`--open` option)\n- **Azure DevOps Integration** - Optional pull request analytics with comprehensive PR workflow insights\n- **Multi-Source Analytics** - Unified Git + Azure DevOps analytics with intelligent correlation\n- **Intelligent Caching** - Multi-level caching for Azure DevOps API with rate limiting\n\nThese capabilities establish a foundation of **analytical honesty and transparency** that guides all development.\n\n### v1.1 (Planned)\n\n- [ ] Branch comparison and diff analysis (`--compare` option)\n- [ ] Continuous monitoring mode (`--watch` option)\n- [ ] Historical trend analysis and forecasting\n- [ ] Advanced temporal coupling analysis\n- [ ] Custom risk scoring models\n- [ ] GitHub pull request integration\n\n### v1.2 (Future)\n\n- [ ] API server mode for remote analysis\n- [ ] Machine learning-based anomaly detection\n- [ ] Integration with code quality tools (SonarQube, CodeClimate)\n- [ ] GitLab merge request integration\n- [ ] Real-time monitoring and alerting\n- [ ] Multi-repository analysis and benchmarking\n- [ ] Advanced visualization with D3.js\n\n### v2.0 (Vision)\n\n- [ ] Web dashboard and UI\n- [ ] Database persistence (SQLite/PostgreSQL)\n- [ ] User authentication and authorization\n- [ ] Team management and permissions\n- [ ] Webhook integrations and notifications\n\n## \ud83d\udcc4 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## \ud83d\ude4f Acknowledgments\n\n- **Git Community** - For the powerful version control system\n- **Open Source Contributors** - For the excellent libraries and tools\n- **Enterprise Users** - For feedback and requirements validation\n- **TypeScript Team** - For the robust type system\n\n## \ud83d\udcde Support\n\n- **Documentation**: [GitHub Wiki](https://github.com/MarkHazleton/git-spark/wiki)\n- **Issues**: [GitHub Issues](https://github.com/MarkHazleton/git-spark/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/MarkHazleton/git-spark/discussions)\n- **Email**: [mark@markhazleton.com](mailto:mark@markhazleton.com)\n\n---\n\n## \ud83d\udc68\u200d\ud83d\udcbb About the Author\n\n**Mark Hazleton** is a passionate software architect and developer with decades of experience building enterprise-scale solutions. As the creator of the **WebSpark** family of tools and frameworks, Mark is committed to empowering developers with practical, honest, and high-quality open-source solutions.\n\n### \ud83c\udf10 Connect with Mark\n\n- **Website**: [markhazleton.com](https://markhazleton.com) - Portfolio, blog, and technical articles\n- **GitHub**: [@MarkHazleton](https://github.com/MarkHazleton) - Open source projects and contributions\n- **LinkedIn**: [Mark Hazleton](https://www.linkedin.com/in/markhazleton/) - Professional network\n- **Email**: [mark@markhazleton.com](mailto:mark@markhazleton.com) - Direct contact\n\n### \ud83d\udcbc Professional Focus\n\nMark specializes in:\n\n- Enterprise application architecture and design\n- Open-source tooling and developer productivity\n- Code quality, analytics, and automation\n- Mentoring and knowledge sharing in the developer community\n\n---\n\n## \u26a1 The WebSpark Family\n\n**Git Spark** is part of the **WebSpark** ecosystem - a growing family of tools, frameworks, and demonstrations designed to solve real-world development challenges with elegance and precision.\n\n### \ud83c\udfaf Other WebSpark Projects\n\n- **WebSpark Demos** - Interactive demonstrations of modern web technologies and architectural patterns\n- **WebSpark Tools** - Productivity utilities for developers and teams\n- **WebSpark Frameworks** - Reusable components and libraries for enterprise applications\n\n### \ud83d\ude80 The WebSpark Philosophy\n\nThe WebSpark family is built on core principles:\n\n- \u2728 **Practical Excellence** - Tools that solve real problems elegantly\n- \ud83d\udd0d **Transparency First** - Honest about capabilities and limitations\n- \ud83c\udf93 **Education Focused** - Empowering developers with knowledge\n- \ud83e\udd1d **Community Driven** - Open source and collaborative\n- \ud83c\udfe2 **Enterprise Ready** - Production-grade quality and reliability\n\n### \ud83c\udf1f Explore More\n\nVisit [markhazleton.com](https://markhazleton.com) to explore the full WebSpark ecosystem and discover tools that can transform your development workflow.\n\n---\n\nBuilt with \u2764\ufe0f and unwavering commitment to analytical honesty for the developer community\n\n> Git Spark prioritizes transparency, accuracy, and user education above all else. We believe developers deserve honest, reliable analytics that clearly communicate both capabilities and limitations.\n"
}