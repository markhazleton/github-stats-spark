{
  "timestamp": "2026-01-03T18:47:46.702600",
  "value": "# \ud83d\uddc4\ufe0f SQL2CSV\n\n[![.NET](https://img.shields.io/badge/.NET-9.0-purple.svg)](https://dotnet.microsoft.com/download)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n[![Build](https://img.shields.io/github/actions/workflow/status/markhazleton/sql2csv/ci.yml?branch=main)](https://github.com/markhazleton/sql2csv/actions)\n[![Coverage](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/markhazleton/sql2csv/main/coverage-badge.json)](#-testing--quality)\n\n> .NET 9 toolkit for discovering SQLite databases, exporting tables to CSV, inspecting schema, and generating C# DTOs. Includes a console CLI and an early-stage web UI scaffold.\n\n## \u2728 Current Core Features (Implemented)\n\n- \ud83d\udd0d SQLite database discovery (directory scanning)\n- \ud83d\udce4 Export all tables (or filtered subset) to CSV (per-table filter via `--tables` or web UI multi-select)\n- \ud83d\udcca Text / JSON / Markdown schema reports (CLI `--format`)\n- \ud83c\udfd7\ufe0f Generate C# DTO classes (future: records + richer docs planned) \u2013 namespace configurable\n- \ud83e\udde9 Reusable core services (discovery / export / schema / code generation)\n- \ud83e\uddea 115 passing tests (MSTest) \u2013 coverage badge published via CI (regression policy enforced)\n- \u2699\ufe0f Options pattern & DI-friendly architecture\n- \ud83d\udcbe Persisted file management (save, list, delete, describe uploaded DBs)\n- \ud83d\udcc8 Dynamic table analysis component (sorting / filtering / pagination)\n\n> NOTE: Code generation table filtering & advanced visualization still pending (see Roadmap Alignment wave).\n\n### CLI Overview\n\n| Command | Description | Key Options |\n|---------|-------------|-------------|\n| discover | List discovered SQLite databases in a directory | --path |\n| export | Export all tables (or filtered subset) to CSV | --path, --output, --delimiter, --headers, --tables |\n| schema | Print schema reports | --path, --format |\n| generate | Generate C# DTO records | --path, --output, --namespace |\n\nPlanned (soon): additional export formats (json, parquet, excel), code template customization.\n\n### CLI Usage Examples\n\n```bash\n# Discover databases\ndotnet run --project sql2csv.console discover --path \"C:\\Data\\DBs\"\n\n# Export databases to CSV (override delimiter and headers)\ndotnet run --project sql2csv.console export --path \"C:\\Data\\DBs\" --output \"C:\\Exports\" --delimiter \";\" --headers true\n\n# Export only specific tables (case-insensitive, comma / semicolon separators)\ndotnet run --project sql2csv.console export --path \"C:\\Data\\DBs\" --tables Users,Orders;Products\n\n# Schema reports\ndotnet run --project sql2csv.console schema --path \"C:\\Data\\DBs\"\n\n# Generate DTOs\ndotnet run --project sql2csv.console generate --path \"C:\\Data\\DBs\" --output \"C:\\Gen\" --namespace \"MyApp.Models\"\n\n# (Preview) Provide tables filter (currently logged; generation still processes all tables)\ndotnet run --project sql2csv.console generate --path \"C:\\Data\\DBs\" --tables Users,Orders\n```\n\n### Architecture Highlights\n\n- Clean separation (Core library reused by console & web)\n- DI + options pattern\n- Structured logging via Microsoft.Extensions.Logging\n- Focused services: discovery / export / schema / code generation\n- Test project validating primary flows\n\n### Web UI (Status: Wave 2 Foundations Implemented)\n\nImplemented:\n\n- Drag & drop upload (header + size validation, immediate analysis redirect)\n- Optional persistence of uploaded DBs with metadata (manage existing files)\n- Multi-table export selection (Select All / Clear All + disabled state)\n- Dynamic data table (server-driven pagination, sorting, filtering)\n- Table filtering integrated in CLI & web export paths\n\nDeferred (future waves): advanced schema visualizations, progress indicators, code generation table filtering, API exposure.\n\n## \ud83d\ude80 Quick Start\n\n### Prerequisites\n\n- [.NET 9.0 SDK](https://dotnet.microsoft.com/download/dotnet/9.0) or later\n- Windows, macOS, or Linux\n- Node.js 18+ (for web application frontend build)\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/markhazleton/sql2csv.git\ncd sql2csv\n\n# Build the entire solution\ndotnet build\n\n# Install frontend dependencies (for web app)\ncd sql2csv.web\nnpm install\nnpm run build\ncd ..\n```\n\n### Run Web (early preview)\n\n```bash\ndotnet run --project sql2csv.web\n# Browse http://localhost:5000\n```\n\n<!-- Verbose marketing demos removed. -->\n\n**\ud83c\udfaf Console Features Showcase:**\n\n- **Smart Discovery Engine**: Recursively finds databases with pattern matching\n- **Parallel Processing**: Multi-threaded operations for maximum performance\n- **Rich Progress Indicators**: Real-time progress with ETA calculations\n- **Detailed Logging**: Configurable log levels with structured output\n- **Error Recovery**: Graceful handling of corrupted or locked databases\n- **Cross-Platform**: Identical functionality on Windows, macOS, and Linux\n\n## \ud83d\udcd6 Documentation\n\n### Commands\n\n#### \ud83d\udd04 Export Command\n\nExports all tables from discovered databases to CSV files:\n\n```bash\ndotnet run export [options]\n```\n\n**Options:**\n\n- `--path`: Directory containing SQLite database files (default: `%LOCALAPPDATA%\\SQL2CSV\\data`)\n- `--output`: Output directory for CSV files (default: `%LOCALAPPDATA%\\SQL2CSV\\export`)\n\n**Example:**\n\n```bash\ndotnet run export --path \"C:\\MyDatabases\" --output \"C:\\MyExports\"\n```\n\n#### \ud83d\udcca Schema Command\n\nGenerates detailed schema reports for all discovered databases in one of three formats (text, json, markdown):\n\n```bash\ndotnet run schema [options]\n```\n\n**Options:**\n\n- `--path`: Directory containing SQLite database files\n- `--format`: Output format: text (default), json, markdown\n\n**Example:**\n\n```bash\n# Default text\ndotnet run schema --path \"C:\\ProjectDatabases\"\n\n# JSON\ndotnet run schema --path \"C:\\ProjectDatabases\" --format json\n\n# Markdown\ndotnet run schema --path \"C:\\ProjectDatabases\" --format markdown > schema.md\n```\n\n#### \ud83c\udfd7\ufe0f Generate Command\n\nGenerates modern C# DTO classes from database schemas:\n\n```bash\ndotnet run generate [options]\n```\n\n**Options:**\n\n- `--path`: Directory containing SQLite database files\n- `--output`: Output directory for generated code (default: `%LOCALAPPDATA%\\SQL2CSV\\generated`)\n- `--namespace`: Namespace for generated classes (default: `Sql2Csv.Generated`)\n\n**Example:**\n\n```bash\ndotnet run generate --path \"C:\\Data\" --output \"C:\\Code\\Models\" --namespace \"MyCompany.Data.Models\"\n```\n\n### Configuration\n\nThe application uses `appsettings.json` for configuration:\n\n```json\n{\n  \"Sql2Csv\": {\n    \"RootPath\": \"C:\\\\Temp\\\\SQL2CSV\",\n    \"Paths\": {\n      \"Config\": \"config\",\n      \"Data\": \"data\", \n      \"Scripts\": \"scripts\"\n    },\n    \"Database\": {\n      \"DefaultName\": \"test.db\",\n      \"Timeout\": 600\n    },\n    \"Export\": {\n      \"IncludeHeaders\": true,\n      \"Delimiter\": \",\",\n      \"Encoding\": \"UTF-8\"\n    }\n  }\n}\n```\n\n## \ud83c\udfd7\ufe0f Project Structure\n\nThis solution follows Clean Architecture principles with clear separation of concerns:\n\n```text\nsql2csv/\n\u251c\u2500\u2500 \ud83c\udf10 sql2csv.web/               # Web Application\n\u2502   \u251c\u2500\u2500 Controllers/              # MVC controllers\n\u2502   \u251c\u2500\u2500 Models/                   # View models and DTOs\n\u2502   \u251c\u2500\u2500 Services/                 # Web-specific services\n\u2502   \u251c\u2500\u2500 Views/                    # Razor views and layouts\n\u2502   \u251c\u2500\u2500 wwwroot/                  # Static files (CSS, JS, images)\n\u2502   \u251c\u2500\u2500 Program.cs               # Web app entry point\n\u2502   \u2514\u2500\u2500 appsettings.json         # Web app configuration\n\u251c\u2500\u2500 \ud83d\udcf1 sql2csv.console/           # Console Application\n\u2502   \u251c\u2500\u2500 Presentation/             # CLI commands and UI logic\n\u2502   \u251c\u2500\u2500 Program.cs               # Console app entry point\n\u2502   \u2514\u2500\u2500 appsettings.json         # Console app configuration\n\u251c\u2500\u2500 \ud83d\udcda Sql2Csv.Core/             # Core Library\n\u2502   \u251c\u2500\u2500 Configuration/           # Configuration models\n\u2502   \u251c\u2500\u2500 Interfaces/              # Service contracts  \n\u2502   \u251c\u2500\u2500 Models/                  # Domain entities\n\u2502   \u2514\u2500\u2500 Services/                # Business logic services\n\u251c\u2500\u2500 \ud83e\uddea Sql2Csv.Tests/            # Test Project\n\u2502   \u2514\u2500\u2500 UnitTest1.cs            # Sample test\n\u251c\u2500\u2500 \ud83d\udcc4 README.md                 # This file\n\u2514\u2500\u2500 \ud83d\udd27 sql2csv.sln              # Solution file\n```\n\n### Core Components\n\n#### \ufffd Web Application\n\nThe web application provides an intuitive interface for database operations:\n\n**Controllers:**\n\n- `HomeController`: Main application flow, file upload, and analysis\n- File management endpoints for CRUD operations\n\n**Services:**\n\n- `WebDatabaseService`: Web-specific database operations with timeout handling\n- `PersistedFileService`: File persistence and metadata management\n\n**Models:**\n\n- `FileUploadViewModel`: File upload and selection interface\n- `FileManagementViewModel`: Persisted file management\n- `PersistedDatabaseFile`: File metadata and tracking\n\n**Features:**\n\n- **File Upload**: Drag-and-drop SQLite file upload with validation\n- **File Persistence**: Save uploaded files with metadata for reuse\n- **Interactive Analysis**: Real-time database schema browsing\n- **Export & Generation**: Web-based CSV export and C# code generation\n\n#### \ufffd\ud83c\udfaf Sql2Csv.Core Library\n\nThe core library contains all business logic and can be referenced by multiple projects:\n\n**Services:**\n\n- `ApplicationService`: Main orchestration service\n- `DatabaseDiscoveryService`: Discovers and validates SQLite database files\n- `ExportService`: High-performance CSV export with rich metadata\n- `SchemaService`: Database schema introspection and reporting\n- `CodeGenerationService`: Template-based C# code generation\n\n**Models:**\n\n- `DatabaseConfiguration`: Database connection settings\n- `TableInfo`, `ColumnInfo`: Schema information models\n- Domain entities for database operations\n\n**Interfaces:**\n\n- `IDatabaseDiscoveryService`: Database discovery contract\n- `IExportService`: CSV export contract\n- `ISchemaService`: Schema operations contract\n- `ICodeGenerationService`: Code generation contract\n\n#### \ud83d\udda5\ufe0f CLI Application\n\nThe console application provides a modern CLI interface:\n\n- **Command Factory**: Creates and configures CLI commands\n- **Dependency Injection**: Configures services and logging\n- **Configuration**: Loads settings from appsettings.json\n- **Error Handling**: Comprehensive error handling and user feedback\n\n### Architecture Benefits\n\n- **\ud83d\udd27 Maintainability**: Clear separation makes code easy to understand and modify\n- **\ud83e\uddea Testability**: Each layer can be unit tested independently\n- **\ud83d\udd04 Flexibility**: Business logic is independent of external frameworks\n- **\ud83d\udcc8 Scalability**: Easy to add new features without affecting existing functionality\n- **\u267b\ufe0f Reusability**: Core library can be used in web apps, APIs, or other applications\n\n## \ud83e\uddea Testing & Quality\n\n### \ud83c\udfaf Comprehensive Test Coverage\n\nOur commitment to quality is demonstrated through extensive testing infrastructure:\n\nCurrent (Aug 2025):\n\n- 115 passing tests (MSTest)\n- Coverage badge published (see badge at top)\n- Benchmarks & extended static analysis planned\n\n### \ud83c\udfd7\ufe0f Test Infrastructure Demos\n\n**\ud83d\udd2c Unit Testing Excellence:**\n\n```csharp\n[TestMethod]\npublic async Task ExportTableToCsvAsync_WithValidTable_ShouldExportSuccessfully()\n{\n    // Arrange: Create test database with sample data\n    var databaseConfig = new DatabaseConfiguration(\"TestDB\", ConnectionString);\n    var outputFilePath = Path.Combine(_outputDirectory, \"users_export.csv\");\n\n    // Act: Export table to CSV\n    var result = await _exportService.ExportTableToCsvAsync(databaseConfig, \"Users\", outputFilePath);\n\n    // Assert: Verify successful export with real data validation\n    result.IsSuccess.Should().BeTrue();\n    result.RowCount.Should().Be(3);\n    \n    var csvContent = await File.ReadAllTextAsync(outputFilePath);\n    csvContent.Should().Contain(\"John Doe\");\n    csvContent.Should().Contain(\"jane@example.com\");\n}\n```\n\n**\u26a1 Integration Testing:**\n\n- **End-to-End Workflows**: Full database discovery \u2192 analysis \u2192 export \u2192 code generation\n- **Real Database Testing**: Tests use actual SQLite databases, not mocks\n- **Cross-Platform Validation**: Automated testing on Windows, macOS, and Linux\n- **Performance Testing**: Benchmarks for large database processing\n\n**\ud83d\udd27 Test Infrastructure Features:**\n\n- **Fluent Assertions**: Beautiful, readable test assertions\n- **Test Data Management**: Automated test database creation and cleanup\n- **Parallel Execution**: Fast test execution with proper isolation\n- **Mock Objects**: Strategic mocking with Moq for external dependencies\n\n### \ufffd\ufe0f Quality Gates & Standards\n\n**Code Quality Metrics:**\n\n- **Static Analysis**: Comprehensive code analysis with industry-standard rules\n- **Dependency Scanning**: Automated vulnerability scanning of all dependencies\n- **Code Style**: Consistent formatting and naming conventions\n- **Documentation Coverage**: XML documentation for all public APIs\n\n**\ud83c\udfaf Quality Standards:**\n\n- **SOLID Principles**: Clean Architecture implementation\n- **Nullable Reference Types**: Modern C# safety features\n- **Async/Await Best Practices**: Proper asynchronous programming patterns\n- **Error Handling**: Comprehensive exception handling and logging\n\n### \ud83d\udd0d Demo Test Scenarios\n\n#### Scenario 1: Large Database Processing\n\n```csharp\n[TestMethod]\npublic async Task ExportDatabasesAsync_WithLargeDatabase_ShouldMaintainPerformance()\n{\n    // Tests processing of databases with 100,000+ records\n    // Validates memory usage and processing time\n    // Ensures consistent performance across different database sizes\n}\n```\n\n#### Scenario 2: Concurrent Operations\n\n```csharp\n[TestMethod]\npublic async Task ParallelExport_WithMultipleDatabases_ShouldNotInterfere()\n{\n    // Tests simultaneous export of multiple databases\n    // Validates thread safety and resource management\n    // Ensures no data corruption or race conditions\n}\n```\n\n#### Scenario 3: Error Recovery\n\n```csharp\n[TestMethod]\npublic async Task ExportTableToCsvAsync_WithCorruptedDatabase_ShouldHandleGracefully()\n{\n    // Tests behavior with corrupted or locked database files\n    // Validates error reporting and recovery mechanisms\n    // Ensures system stability under adverse conditions\n}\n```\n\nFurther coverage & benchmark reporting will be integrated via CI.\n\n### Building\n\n```bash\n# Build the entire solution\ndotnet build\n\n# Build specific project\ndotnet build sql2csv.console/Sql2Csv.csproj\n```\n\n### Testing\n\n```bash\n# Run all tests\ndotnet test\n\n# Run tests with coverage\ndotnet test --collect:\"XPlat Code Coverage\"\n```\n\n### Publishing\n\n```bash\n# Publish for Windows x64\ndotnet publish sql2csv.console/Sql2Csv.csproj -c Release -r win-x64 --self-contained\n\n# Publish for Linux x64\ndotnet publish sql2csv.console/Sql2Csv.csproj -c Release -r linux-x64 --self-contained\n\n# Publish for macOS x64\ndotnet publish sql2csv.console/Sql2Csv.csproj -c Release -r osx-x64 --self-contained\n```\n\n## \ud83d\udcca Sample Output\n\n### \ud83c\udfac Live CSV Export Demo\n\nOur advanced export engine creates perfectly formatted CSV files with rich metadata:\n\n```csv\n# Example: Users table export (Users_extract.csv)\nId,Name,Email,Age,CreatedDate\n1,\"John Doe\",\"john@example.com\",30,\"2024-01-15T10:30:00Z\"\n2,\"Jane Smith\",\"jane@example.com\",25,\"2024-01-16T14:22:00Z\"\n3,\"Bob Johnson\",\"bob@example.com\",35,\"2024-01-17T09:15:00Z\"\n```\n\n**Advanced Export Features:**\n\n- Creates organized directory structure: `{DatabaseName}/{TableName}_extract.csv`\n- Configurable headers, delimiters (`,`, `;`, `|`, `\\t`)\n- Proper CSV escaping with CsvHelper for complex data\n- Custom encoding support (UTF-8, UTF-16, ASCII)\n- Batch processing with progress tracking\n- Error handling with detailed failure reports\n\n### \ud83c\udfd7\ufe0f Generated C# Code Showcase\n\nExperience our intelligent code generation that creates modern, documented C# classes:\n\n```csharp\nnamespace MyCompany.Data.Models;\n\n/// <summary>\n/// Data Transfer Object for Users table\n/// Generated on 2024-01-15 at 10:30:00 UTC\n/// </summary>\npublic record User\n{\n    /// <summary>\n    /// Primary key identifier (INTEGER, NOT NULL)\n    /// </summary>\n    public int Id { get; init; }\n    \n    /// <summary>\n    /// User's full name (TEXT, NOT NULL)\n    /// </summary>\n    public string Name { get; init; } = string.Empty;\n    \n    /// <summary>\n    /// User's email address (TEXT, NULLABLE)\n    /// </summary>\n    public string? Email { get; init; }\n    \n    /// <summary>\n    /// User's age in years (INTEGER, NULLABLE)\n    /// </summary>\n    public int? Age { get; init; }\n    \n    /// <summary>\n    /// Record creation timestamp (TEXT, DEFAULT: CURRENT_TIMESTAMP)\n    /// </summary>\n    public string? CreatedDate { get; init; }\n}\n\n/// <summary>\n/// Data Transfer Object for Orders table\n/// Foreign Key: UserId references Users.Id\n/// </summary>\npublic record Order\n{\n    public int Id { get; init; }\n    public int? UserId { get; init; }\n    public double? Amount { get; init; }\n    public string? OrderDate { get; init; }\n    \n    /// <summary>\n    /// Navigation property to related User\n    /// </summary>\n    public User? User { get; init; }\n}\n```\n\n**\ud83c\udfa8 Code Generation Features:**\n\n- **Modern C# Patterns**: Records, nullable reference types, init-only properties\n- **Rich Documentation**: XML comments with data types and constraints\n- **Intelligent Naming**: PascalCase conversion from database naming conventions\n- **Relationship Mapping**: Foreign key detection with navigation properties\n- **Flexible Output**: Support for classes, records, and interfaces\n- **Custom Templates**: Configurable code generation templates\n\n### \ud83d\udccb Comprehensive Schema Reports\n\nOur schema analysis provides detailed insights into database structure:\n\n```text\n========================================\nDATABASE SCHEMA REPORT\n========================================\nDatabase: MyProject.db\nGenerated: 2024-01-15 10:30:00 UTC\nTotal Tables: 3\nTotal Columns: 15\n========================================\n\nTABLE: Users (main)\n  Rows: 1,247\n  Columns: 5\n  Primary Key: Id (INTEGER)\n  \n  COLUMNS:\n  \u251c\u2500 Id          \u2502 INTEGER \u2502 PK \u2502 NOT NULL \u2502 AUTOINCREMENT\n  \u251c\u2500 Name        \u2502 TEXT    \u2502    \u2502 NOT NULL \u2502\n  \u251c\u2500 Email       \u2502 TEXT    \u2502    \u2502 NULL     \u2502 UNIQUE\n  \u251c\u2500 Age         \u2502 INTEGER \u2502    \u2502 NULL     \u2502\n  \u2514\u2500 CreatedDate \u2502 TEXT    \u2502    \u2502 NULL     \u2502 DEFAULT: CURRENT_TIMESTAMP\n\nTABLE: Orders (main)\n  Rows: 3,891\n  Columns: 4\n  Primary Key: Id (INTEGER)\n  Foreign Keys: UserId \u2192 Users.Id\n  \n  COLUMNS:\n  \u251c\u2500 Id        \u2502 INTEGER \u2502 PK \u2502 NOT NULL \u2502 AUTOINCREMENT\n  \u251c\u2500 UserId    \u2502 INTEGER \u2502 FK \u2502 NULL     \u2502 \u2192 Users.Id\n  \u251c\u2500 Amount    \u2502 REAL    \u2502    \u2502 NULL     \u2502\n  \u2514\u2500 OrderDate \u2502 TEXT    \u2502    \u2502 NULL     \u2502 DEFAULT: CURRENT_TIMESTAMP\n\nTABLE: Products (main)\n  Rows: 156\n  Columns: 4\n  Primary Key: Id (INTEGER)\n  \n  COLUMNS:\n  \u251c\u2500 Id          \u2502 INTEGER \u2502 PK \u2502 NOT NULL \u2502 AUTOINCREMENT\n  \u251c\u2500 Name        \u2502 TEXT    \u2502    \u2502 NOT NULL \u2502\n  \u251c\u2500 Price       \u2502 REAL    \u2502    \u2502 NULL     \u2502\n  \u2514\u2500 Description \u2502 TEXT    \u2502    \u2502 NULL     \u2502\n\n========================================\nRELATIONSHIPS:\nOrders.UserId \u2192 Users.Id (Many-to-One)\n\nINDEXES:\nUsers.Email (UNIQUE)\n\nSTATISTICS:\nTotal Records: 5,294\nAverage Records per Table: 1,765\nLargest Table: Orders (3,891 rows)\n========================================\n```\n\n**\ud83d\udcca Schema Analysis Features:**\n\n- **Visual Tree Structure**: Beautiful ASCII art representation\n- **Relationship Mapping**: Foreign key detection and visualization\n- **Statistical Analysis**: Row counts, data distribution, and table sizes\n- **Index Information**: Index types and performance implications\n- **Data Type Analysis**: Type mapping and nullable constraints\n- **Export Options**: JSON, XML, and markdown format support\n\n## \ud83c\udfaf Typical Use Cases\n\n### \ud83d\udd0d Interactive Database Analysis & Development\n\n**\ud83c\udfac Demo Scenario**: A development team needs to quickly understand a legacy SQLite database structure.\n\n- **Instant Database Upload**: Drag the database file into the web interface\n- **Live Schema Exploration**: Browse all tables, columns, and relationships interactively\n- **Data Sampling**: View actual data with filtering and search capabilities\n- **Documentation Generation**: Export schema reports for team documentation\n- **Code Integration**: Generate C# models for immediate use in applications\n\n**Real Benefits**: Teams save hours of manual database exploration and documentation work.\n\n### \ud83d\ude9a Enterprise Data Migration Projects\n\n**\ud83c\udfac Demo Scenario**: Migrating from legacy SQLite databases to modern SQL Server.\n\n```bash\n# Discover all databases across multiple directories\ndotnet run discover --path \"C:\\LegacyData\" --recursive true\n\n# Export all data to CSV for analysis and migration scripts\ndotnet run export --path \"C:\\LegacyData\" --output \"C:\\Migration\\CSVs\" --delimiter \"|\"\n\n# Generate C# models for the new application layer\ndotnet run generate --path \"C:\\LegacyData\" --namespace \"NewApp.Entities\" --type \"record\"\n```\n\n**Real Benefits**: Automated discovery and export of hundreds of databases, saving weeks of manual work.\n\n### \ud83c\udfd7\ufe0f Modern Code Generation for APIs\n\n**\ud83c\udfac Demo Scenario**: Building REST APIs that need DTOs matching existing database schemas.\n\n- **Bulk Code Generation**: Generate DTOs for entire database collections\n- **Modern C# Features**: Records, nullable reference types, and init-only properties\n- **Custom Namespaces**: Organize generated code into proper project structure\n- **Documentation**: Rich XML comments with database metadata\n\n**Real Benefits**: Consistent, well-documented DTOs generated in minutes instead of hours of manual coding.\n\n### \ud83d\udcca Business Intelligence & Data Analysis\n\n**\ud83c\udfac Demo Scenario**: Analysts need CSV exports for Excel/Power BI reporting.\n\n- **Selective Export**: Choose specific tables through the web interface\n- **Custom Formatting**: Configure delimiters and encoding for target systems\n- **Batch Processing**: Export multiple databases simultaneously\n- **Progress Tracking**: Real-time progress for large datasets\n\n**Real Benefits**: Self-service data extraction without IT intervention, enabling faster business insights.\n\n### \ud83d\udd04 Database Backup & Archival\n\n**\ud83c\udfac Demo Scenario**: Creating human-readable backups of critical SQLite databases.\n\n- **Automated Discovery**: Find all databases in backup directories\n- **Comprehensive Export**: Export all tables to organized CSV structure\n- **Schema Documentation**: Generate reports for archive documentation\n- **Verification**: Built-in validation ensures complete data export\n\n**Real Benefits**: Reliable, auditable backups that can be restored without specialized tools.\n\n### \ud83d\udc65 Team Collaboration & Documentation\n\n**\ud83c\udfac Demo Scenario**: Sharing database analysis across development teams.\n\n- **File Persistence**: Save analyzed databases for team access\n- **Metadata Tracking**: Description, tags, and access history\n- **Schema Sharing**: Export schema reports in multiple formats\n- **Code Sharing**: Generate and distribute consistent DTOs\n\n**Real Benefits**: Centralized database knowledge base that improves team productivity and reduces duplicate work.\n\n## \ud83d\udd27 Advanced Usage\n\n### Using the Core Library\n\n```csharp\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Logging;\nusing Sql2Csv.Core.Configuration;\nusing Sql2Csv.Core.Services;\n\n// Setup dependency injection\nvar services = new ServiceCollection();\nservices.AddLogging(builder => builder.AddConsole());\nservices.Configure<Sql2CsvOptions>(config => \n{\n    config.Export.IncludeHeaders = true;\n    config.Export.Delimiter = \",\";\n});\n\n// Register core services\nservices.AddScoped<IDatabaseDiscoveryService, DatabaseDiscoveryService>();\nservices.AddScoped<IExportService, ExportService>();\nservices.AddScoped<ISchemaService, SchemaService>();\nservices.AddScoped<ICodeGenerationService, CodeGenerationService>();\nservices.AddScoped<ApplicationService>();\n\nvar serviceProvider = services.BuildServiceProvider();\n\n// Use the services\nvar app = serviceProvider.GetRequiredService<ApplicationService>();\nawait app.ExportDatabasesAsync(\"C:\\\\Data\", \"C:\\\\Export\");\n```\n\n### Custom Configuration\n\n```csharp\n// Custom CSV export settings\nvar options = new Sql2CsvOptions\n{\n    Export = new ExportOptions\n    {\n        IncludeHeaders = false,\n        Delimiter = \"|\",\n        Encoding = \"UTF-8\"\n    }\n};\n```\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.\n\n### Development Setup\n\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature/amazing-feature`\n3. Make your changes and add tests\n4. Ensure all tests pass: `dotnet test`\n5. Commit your changes: `git commit -m 'Add amazing feature'`\n6. Push to the branch: `git push origin feature/amazing-feature`\n7. Open a Pull Request\n\n### Code Style\n\n- Follow [Microsoft C# Coding Conventions](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions)\n- Use nullable reference types\n- Include XML documentation for public APIs\n- Write unit tests for new functionality\n\n## \ud83d\udccb Roadmap\n\nRoadmap waves summarized (see `ISSUE_LIST.md` for full backlog & sequencing):\n\n### \u2705 Completed (select highlights)\n\n- CI workflow (build + test + coverage publishing, badge commit)\n- Coverage badge JSON endpoint integration\n- Export delimiter & header overrides\n- Schema report alternative formats (json, markdown)\n- Web UI foundations: upload, multi-select export, persisted file management\n- Cross-platform path normalization fixes\n\n### \ud83d\udd27 Wave 2.5 (Alignment & Hardening)\n\n- README roadmap realignment (done)\n- Apply tables filter to code generation\n- Implement schema table filtering\n- Web integration tests (upload + filtered export)\n- DTO parity (records + XML docs) & optional record/class switch\n- Exit code consistency for zero-match filters\n- ExportService overload consolidation\n- ADR for plugin/provider architecture\n\n### \ud83d\udce6 Wave 3 (Packaging, Performance & Formats)\n\n- Docker packaging (console + web)\n- Benchmark suite (BenchmarkDotNet)\n- Advanced export formats (JSON data export, Parquet, Excel)\n\n### \ud83c\udf10 Wave 4 (Platform & Extensibility)\n\n- REST API + OpenAPI (Swagger)\n- Plugin architecture (exporters / code templates)\n- Additional database providers (PostgreSQL first, then others)\n\n### \ud83d\udd10 Wave 5 (Security, Globalization, Polish)\n\n- Auth & RBAC (web/API)\n- Internationalization (resource files + locale switch)\n- Contributor documentation & examples\n\nContributions welcome\u2014open an issue or pick from the alignment wave for fast feedback.\n\n## \ud83d\udcc4 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## \ud83d\ude4b\u200d\u2642\ufe0f Support\n\n- \ud83d\udce7 **Issues**: [GitHub Issues](https://github.com/markhazleton/sql2csv/issues)\n- \ud83d\udcac **Discussions**: [GitHub Discussions](https://github.com/markhazleton/sql2csv/discussions)\n- \ud83d\udcd6 **Documentation**: [Wiki](https://github.com/markhazleton/sql2csv/wiki)\n\n## \u2b50 Show Your Support\n\nGive a \u2b50\ufe0f if this project helped you!\n\n---\n\nMade with \u2764\ufe0f by [Mark Hazleton](https://github.com/markhazleton)\n"
}