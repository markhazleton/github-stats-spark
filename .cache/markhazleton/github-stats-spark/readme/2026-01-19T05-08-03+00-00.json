{
  "timestamp": "2026-01-19T05:18:40.455322+00:00",
  "value": "# Stats Spark \u26a1\n\n> Automated GitHub profile statistics generator with beautiful SVG visualizations and AI-powered repository analysis\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)\n\n**\ud83d\udcca [View Sample Analysis Report](output/reports/markhazleton-analysis.md)** - See real-world output with AI-powered insights\n**\ud83c\udfa8 [View Interactive Dashboard](https://markhazleton.github.io/github-stats-spark/)** - Explore repositories with live visualizations\n\n---\n\n## \ud83c\udfaf What is Stats Spark?\n\nStats Spark is a comprehensive GitHub analytics suite that transforms your GitHub activity into actionable insights and stunning visualizations. It combines automated SVG generation for profile statistics with AI-powered repository analysis to give you a complete picture of your development work.\n\n**Perfect for:**\n\n- \ud83d\udc68\u200d\ud83d\udcbb Developers wanting to showcase their GitHub activity professionally\n- \ud83d\udcca Teams analyzing repository health and contribution patterns\n- \ud83c\udfaf Technical leaders reviewing developer productivity and technology usage\n- \ud83d\ude80 Open source maintainers tracking project momentum and community engagement\n\n## \ud83c\udf1f Why Stats Spark?\n\n### Beautiful Profile Statistics\n\n- **Automated Daily Updates**: GitHub Actions workflow runs at midnight UTC\n- **5 Visual Categories**: Overview, heatmap, languages, streaks, and fun stats\n- **Unique Spark Score**: 0-100 metric combining consistency, volume, and collaboration\n- **Theme Customization**: Dark, light, and custom themes with WCAG AA accessibility\n- **Zero Maintenance**: Set it once, updates automatically forever\n\n### AI-Powered Analysis\n\n- **Intelligent Repository Ranking**: Composite algorithm weighing popularity, activity, and health\n- **AI-Generated Summaries**: Claude Haiku creates technical summaries with 97%+ success rate\n- **Developer Profiling**: Technology diversity, activity patterns, contribution classification\n- **Comprehensive Reports**: GitHub-flavored markdown with embedded visualizations\n- **Performance Optimized**: Analyze 50+ repositories in under 3 minutes\n\n### Interactive Dashboard (NEW!)\n\n- **Mobile-First Design**: Touch-optimized interface with 44x44px touch targets and responsive layouts (320px-768px viewports)\n- **Bottom Sheet Navigation**: Native mobile patterns for filters, sort controls, and detailed views\n- **Swipe Gestures**: Touch-friendly interactions including swipe-to-delete and horizontal navigation\n- **Repository Comparison**: Side-by-side comparison of up to 5 repositories with color-coded metrics\n- **Visual Analytics**: Interactive Chart.js visualizations optimized for mobile with touch tooltips\n- **Drill-Down Details**: Comprehensive repository analysis with commit history and tech stack\n- **Export Functionality**: Download filtered data as CSV or JSON\n- **Performance Optimized**: <2s First Contentful Paint, <5s Time to Interactive on 3G connections\n- **Offline Support**: IndexedDB caching for offline access (coming soon)\n- **Accessibility**: WCAG 2.1 AA compliant with screen reader support and keyboard navigation\n- **GitHub Pages Deployment**: Automatically updates with your latest statistics\n\n### Enterprise-Ready\n\n- **Smart Caching**: Intelligent API request optimization\n- **Rate Limit Handling**: Automatic retry with exponential backoff\n- **Flexible Configuration**: YAML-based configuration for all options\n- **Local Development**: Full CLI for testing before deployment\n- **Extensible Architecture**: Modular design for easy customization\n\nStats Spark automatically analyzes your GitHub activity and generates stunning SVG visualizations that you can embed in your profile README. Get insights into your coding patterns, track your streaks, and showcase your Spark Score!\n\n## \u2728 Features\n\n### \ud83d\udcca SVG Profile Statistics\n\nGenerate beautiful, embeddable SVG visualizations that update automatically:\n\n#### Overview Dashboard\n\n- \u26a1 **Spark Score**: Unique 0-100 metric (40% consistency, 35% volume, 25% collaboration)\n- \ud83d\udcc8 **Key Metrics**: Total commits, repositories, languages, active days\n- \u23f0 **Activity Patterns**: Identify your peak coding hours (night owl, early bird, daytime coder)\n- \u26a1 **Lightning Rating**: 1-5 bolts based on your overall activity level\n\n#### Commit Heatmap\n\n- \ud83d\udcc5 **Calendar View**: GitHub-style contribution calendar\n- \ud83d\udd25 **Intensity Visualization**: Color-coded commit frequency\n- \ud83d\udcca **Pattern Recognition**: Identify consistency and work rhythms\n\n#### Language Statistics\n\n- \ud83c\udf10 **Technology Stack**: Comprehensive language breakdown with percentages\n- \ud83d\udcca **Visual Distribution**: Clean bar charts showing language usage\n- \ud83c\udfaf **Diversity Metrics**: Track your polyglot programming journey\n\n#### Streaks & Consistency\n\n- \ud83d\udd25 **Current Streak**: Active coding streak counter\n- \ud83c\udfc6 **Longest Streak**: Your personal best\n- \ud83d\udcc8 **Consistency Tracking**: Visualize regular contribution patterns\n\n#### Fun Stats \u26a1 ENHANCED\n\n8 personality-driven achievements with emoji flair:\n\n- \ud83e\udd89 **Coding Time Personality**: Night Owl, Early Bird, or Daytime Coder\n- \ud83d\ude80 **Commit Velocity**: From \"Quality over Quantity\" to \"Commit Machine\"\n- \ud83d\udcda **Repository Collection**: Achievement tiers from Focused to Collector\n- \ud83c\udf10 **Language Diversity**: Specialist to Polyglot Programmer\n- \u2b50 **Community Recognition**: Stars earned across all repositories\n- \ud83c\udfdb\ufe0f **Account Longevity**: Experience badges from newcomer to veteran\n- \ud83d\udca5 **Commit Milestones**: Total commits with achievement levels\n- \ud83c\udf19 **Pattern Personality**: Custom messages based on coding style\n\n#### Release Cadence\n\n- \ud83d\udcca **Sparklines**: Weekly and monthly repository diversity\n- \ud83d\ude80 **Activity Breadth**: Highlight breadth of work across projects\n- \ud83d\udcc8 **Trend Visualization**: Track activity patterns over time\n\n### \ud83e\udd16 AI-Powered Repository Analysis\n\nGenerate comprehensive markdown reports with intelligent insights:\n\n#### Intelligent Repository Ranking\n\n- **30% Popularity Weight**: Stars and forks from community engagement\n- **45% Activity Weight**: Recent commits with time-decay (90d/180d/365d windows)\n- **25% Health Weight**: Documentation, licensing, and maintenance signals\n- **Smart Algorithm**: Balances established projects with active development\n\n#### AI-Generated Technical Summaries\n\n- **Claude Haiku Integration**: Enterprise-grade AI summaries for each repository\n- **Three-Tier Fallback**: Claude \u2192 README extraction \u2192 Basic metadata\n- **97%+ Success Rate**: Consistent high-quality summaries\n- **Technical Focus**: Architecture, tech stack, use cases, and unique features\n\n#### Developer Profile Analysis\n\n- **Technology Diversity**: Language usage patterns and specialization metrics\n- **Activity Patterns**: Coding time preferences and consistency analysis\n- **Contribution Classification**: Creator, contributor, maintainer patterns\n- **Observable Trends**: Long-term patterns and development focus areas\n\n#### Comprehensive Reports\n\n- **GitHub-Flavored Markdown**: Perfect formatting for GitHub rendering\n- **Embedded Visualizations**: Includes all SVG statistics inline\n- **Rich Metadata**: Stars, forks, commits, languages, file sizes\n- **Quality Indicators**: License and documentation status badges\n- **Navigation**: Quick links to jump between sections\n\n#### Performance & Reliability\n\n- \u26a1 **Fast**: <1 minute for typical weekly updates (with smart cache refresh)\n- \ud83d\udd04 **Smart Caching**: Reduces API calls by 80-95% through intelligent cache invalidation\n- \ud83e\udde0 **Intelligent Refresh**: Only updates repositories with new commits\n- \ud83d\udee1\ufe0f **Rate Limit Safe**: Automatic handling and retry logic\n- \ud83d\udcca **Progress Tracking**: Real-time feedback during generation\n- \u267f **Accessible**: WCAG AA compliant visualizations\n\n### \ud83d\udd27 Developer Features\n\n- **\ud83c\udfaf Selective Output**: Choose which statistics and reports to generate\n- **\ud83d\udda5\ufe0f Local CLI**: Full command-line interface for testing and development\n- **\ud83d\udcdd YAML Configuration**: Centralized configuration for themes, options, and behavior\n- **\ud83d\ude80 GitHub Actions**: Pre-configured workflow for automated daily updates\n- **\ud83c\udfa8 Custom Themes**: Define your own color schemes and styles\n- **\ud83d\udce6 Modular Architecture**: Clean separation of concerns for easy extension\n- **\ud83e\uddea Comprehensive Tests**: 52% overall coverage (80%+ on core modules)\n- **\ud83d\udcda Full Documentation**: Detailed guides, API reference, and examples\n\n## \ud83d\ude80 Quick Start\n\n### \u26a1 Unified Pipeline Script (Recommended)\n\nThe easiest way to run the complete 4-phase pipeline:\n\n```powershell\n# Windows PowerShell\n.\\run-spark.ps1 -User YOUR_USERNAME -IncludeAI -Verbose\n\n# Check environment first\n.\\run-spark.ps1 -CheckOnly\n```\n\n**Script handles:**\n- \u2705 Environment validation (virtual env, tokens, config)\n- \u2705 Python package installation\n- \u2705 Cache management\n- \u2705 Complete 4-phase pipeline execution\n- \u2705 Output verification and summary\n\n**Options:**\n- `-User` - GitHub username (default: markhazleton)\n- `-IncludeAI` - Generate AI summaries\n- `-ClearCache` - Clear all caches before running\n- `-ForceRefresh` - Force refresh all data\n- `-Verbose` - Enable detailed logging\n- `-CheckOnly` - Validate environment only\n\n### \ud83d\udce6 Manual Setup & CLI\n\nFor direct Python CLI usage:\n\n```bash\n# 1. Install dependencies\npython -m venv .venv\nsource .venv/bin/activate  # Unix/Mac\n# .\\.venv\\Scripts\\Activate.ps1  # Windows\npip install -r requirements.txt\npip install -e .\n\n# 2. Set environment variables\nexport GITHUB_TOKEN=your_github_token_here\nexport ANTHROPIC_API_KEY=your_anthropic_key_here  # Optional\n\n# 3. Run unified command\nspark unified --user YOUR_GITHUB_USERNAME --include-ai-summaries\n```\n\n**This single command generates:**\n- \u2705 `/data/repositories.json` - Complete unified dataset for frontend\n- \u2705 `/output/*.svg` - All 6 visual analytics (overview, heatmap, languages, streaks, fun, release)\n- \u2705 `/output/reports/*.md` - Comprehensive markdown analysis report\n- \u2705 AI summaries for each repository (if API key provided)\n\n**Benefits:**\n- \ud83d\ude80 ~60% faster than separate commands\n- \ud83d\udcbe Single API pass (fewer rate limit issues)\n- \ud83c\udfaf Consistent data snapshot across all outputs\n- \u26a1 Optimized data gathering and caching\n\n**Testing/Debugging Options:**\n\n```bash\n# Test with only 2 repositories (fast cache validation)\nspark unified --user YOUR_USERNAME --max-repos 2\n\n# Force refresh all data (bypass cache)\nspark unified --user YOUR_USERNAME --force-refresh\n\n# Verbose logging for debugging\nspark unified --user YOUR_USERNAME --verbose\n```\n\nSee [QUICKSTART_UNIFIED.md](documentation/QUICKSTART_UNIFIED.md) for detailed instructions.\n\n---\n\n### GitHub Actions Automation\n\n**Or** set up automatic daily updates:\n\n### 1. Fork This Repository\n\nClick the \"Fork\" button in the top right to create your own copy.\n\n### 2. Enable GitHub Actions\n\n1. Go to **Settings** \u2192 **Actions** \u2192 **General**\n2. Select \"Allow all actions and reusable workflows\"\n3. Click **Save**\n\n### 3. Run the Workflow\n\n1. Navigate to **Actions** tab\n2. Select \"Generate GitHub Statistics\"\n3. Click \"Run workflow\" \u2192 \"Run workflow\"\n4. Wait 2-5 minutes for completion\n\n### 4. Embed in Your Profile\n\nAdd to your profile README (`username/username/README.md`):\n\n```markdown\n![GitHub Stats](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/overview.svg)\n```\n\n**Replace `YOUR_USERNAME`** with your GitHub username!\n\nFull instructions: [Getting Started Guide](documentation/guides/getting-started.md)\n\n## \ud83d\udcca Statistics Categories\n\nStats Spark generates 5 SVG categories for your GitHub profile:\n\n| Category | Description | Output File | Sample |\n|----------|-------------|-------------|--------|\n| **Overview** | Spark Score, commits, languages, time pattern | `overview.svg` | ![Overview](output/overview.svg) |\n| **Heatmap** | Commit frequency calendar | `heatmap.svg` | ![Heatmap](output/heatmap.svg) |\n| **Languages** | Programming language breakdown | `languages.svg` | ![Languages](output/languages.svg) |\n| **Streaks** | Current and longest coding streaks | `streaks.svg` | ![Streaks](output/streaks.svg) |\n| **Fun Stats** \u26a1 | 8 personality-driven achievements | `fun.svg` | ![Fun Stats](output/fun.svg) |\n| **Release Cadence** | Weekly + monthly repo diversity sparklines | `release.svg` | ![Release](output/release.svg) |\n\n### \u26a1 Enhanced Fun Stats (New!)\n\nThe Fun Stats visualization now showcases **8 creative measurements** with personality:\n\n- \ud83e\udd89 **Coding Time Personality** - Night Owl, Early Bird, or Daytime Coder\n- \ud83d\ude80 **Commit Velocity** - From \"Quality over Quantity\" to \"Commit Machine\"\n- \ud83d\udcda **Repository Collection** - Achievement tiers from Focused to Collector\n- \ud83c\udf10 **Language Diversity** - Specialist to Polyglot Programmer\n- \u2b50 **Community Recognition** - Stars earned across all repositories\n- \ud83c\udfdb\ufe0f **Account Longevity** - Experience badges from newcomer to veteran\n- \ud83d\udca5 **Commit Milestones** - Total commits with achievement levels\n- \ud83c\udf19 **Pattern Personality** - Custom messages based on your coding style\n\n---\n\n## \ud83e\udd16 Repository Analysis Reports\n\nStats Spark's AI-powered analysis feature generates comprehensive markdown reports that showcase your complete GitHub profile:\n\n### Report Structure\n\n1. **Profile Overview Section**\n   - Embedded SVG visualizations (all 5 categories)\n   - Quick navigation links to major sections\n   - Generation metadata and statistics\n\n2. **Top Repositories Listing** (default: top 50)\n   - Ranked by composite algorithm (popularity + activity + health)\n   - AI-generated technical summaries for each repository\n   - Rich metadata: stars, forks, languages, commit activity\n   - Quality indicators: license and documentation badges\n   - Repository statistics: contributors, file size, commit velocity\n\n3. **Developer Profile Insights**\n   - Overall technology diversity and language specialization\n   - Activity patterns and coding time preferences\n   - Contribution classification (creator vs. contributor)\n   - Observable trends and development focus\n\n4. **Report Metadata**\n   - Generation timestamp and version information\n   - AI summary success rate and coverage statistics\n   - Tool attribution and data sources\n\n### Sample Output\n\n**\ud83d\udcca [View Full Sample Report](output/reports/markhazleton-analysis.md)**\n\nThe sample report demonstrates:\n\n- \u2705 48 repositories analyzed with 97.9% AI summary success rate\n- \u2705 Detailed technical summaries for each major project\n- \u2705 Complete activity visualizations and metrics\n- \u2705 Professional GitHub-flavored markdown formatting\n- \u2705 Easy navigation and comprehensive insights\n\n## \u26a1 Spark Score\n\nThe Spark Score is a 0-100 metric reflecting your GitHub activity:\n\n**Formula**: `40% Consistency + 35% Volume + 25% Collaboration`\n\n**Lightning Rating**: 1-5 bolts based on your score\n\n- \u26a1\u26a1\u26a1\u26a1\u26a1 (80-100): Exceptional\n- \u26a1\u26a1\u26a1\u26a1 (60-79): Strong\n- \u26a1\u26a1\u26a1 (40-59): Good\n- \u26a1\u26a1 (20-39): Growing\n- \u26a1 (0-19): Starting\n\n## \ud83c\udfa8 Themes\n\n- **spark-dark** (default): Dark theme with electric blue and gold\n- **spark-light**: Light theme with WCAG AA colors\n- **custom**: Define your own in `config/themes.yml`\n\nSee [Configuration Guide](documentation/guides/configuration.md) for theme customization.\n\n## \ud83d\udcbb Local CLI\n\nStats Spark provides a comprehensive command-line interface for local development and testing.\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/YOUR_USERNAME/github-stats-spark.git\ncd github-stats-spark\n\n# Install dependencies\npip install -r requirements.txt\n\n# Set up environment variables\nexport GITHUB_TOKEN=your_github_token\nexport ANTHROPIC_API_KEY=your_anthropic_key  # Optional for AI summaries\n```\n\n### Generate SVG Statistics\n\nCreate beautiful visualizations for your GitHub profile:\n\n```bash\n# Generate all statistics\nspark generate --user YOUR_USERNAME\n\n# Generate specific categories\nspark generate --user YOUR_USERNAME --categories overview,heatmap,languages\n\n# Use custom theme\nspark generate --user YOUR_USERNAME --theme spark-dark\n\n# Specify output directory\nspark generate --user YOUR_USERNAME --output ./my-stats\n\n# Preview theme without generating\nspark preview --theme spark-dark\n\n# Validate configuration\nspark config --validate\n```\n\n### \ud83c\udd95 Generate AI-Powered Analysis Reports\n\nCreate comprehensive markdown reports with repository analysis:\n\n```bash\n# Analyze top 50 repositories and generate full report\nspark analyze --user YOUR_USERNAME\n\n# List top repositories without generating report (dry-run)\nspark analyze --user YOUR_USERNAME --list-only\n\n# Customize analysis\nspark analyze --user YOUR_USERNAME --top-n 25 --output output/reports\n\n# Analyze without AI summaries (faster, uses README extraction)\nspark analyze --user YOUR_USERNAME --no-ai\n\n# Verbose output for debugging\nspark analyze --user YOUR_USERNAME --verbose\n```\n\n**Analysis Command Features**:\n\n- \ud83d\udcca Intelligent repository ranking with composite scoring\n- \ud83e\udd16 AI-powered technical summaries (requires ANTHROPIC_API_KEY)\n- \ud83d\udcc8 Multi-window activity analysis (90d/180d/365d)\n- \ud83d\udc64 Developer profile generation with observable patterns\n- \ud83d\udcdd GitHub-flavored markdown output with embedded visualizations\n- \u26a1 High performance: <3 minutes for 50 repositories\n- \ud83d\udd04 Smart caching to minimize API calls\n\n**Options**:\n\n- `--user USERNAME`: GitHub username to analyze (required)\n- `--top-n N`: Number of top repositories to include (default: 50)\n- `--output DIR`: Output directory for reports (default: output/reports)\n- `--list-only`: List top repositories without generating report\n- `--no-ai`: Skip AI summaries, use README extraction only\n- `--verbose`: Enable detailed logging\n\nSee [Analyze Command Guide](documentation/guides/analyze-command.md) for detailed documentation.\n\n## \ud83d\udcda Documentation\n\nComprehensive guides and references for all features:\n\n### Getting Started\n\n- **[Getting Started Guide](documentation/guides/getting-started.md)** - Complete setup instructions for GitHub Actions\n- **[Configuration Guide](documentation/guides/configuration.md)** - All configuration options and customization\n- **[Embedding Guide](documentation/guides/embedding-guide.md)** - How to embed SVGs in your profile README\n\n### Feature Documentation\n\n- **[Analyze Command Guide](documentation/guides/analyze-command.md)** - AI-powered repository analysis deep dive\n- **[API Reference](documentation/api/api-reference.md)** - Developer documentation for core modules\n- **[Changelog](documentation/CHANGELOG.md)** - Version history and release notes\n\n### Examples\n\n- **[Sample Analysis Report](output/reports/markhazleton-analysis.md)** - Real-world output with 48 repositories\n- **[Theme Gallery](config/themes.yml)** - Available themes and customization options\n\n### Support\n\n- **[Issues](https://github.com/markhazleton/github-stats-spark/issues)** - Report bugs or request features\n- **[Discussions](https://github.com/markhazleton/github-stats-spark/discussions)** - Ask questions and share ideas\n\n## \ud83d\udd27 Troubleshooting\n\n### Common Issues\n\n#### GitHub Actions Workflow Fails\n\n**Problem**: Workflow runs but doesn't complete successfully\n\n**Solutions**:\n\n1. Check Actions logs in the Actions tab\n2. Verify GitHub Actions is enabled: Settings \u2192 Actions \u2192 General\n3. Ensure `GITHUB_TOKEN` permissions are correct\n4. Check if rate limits were hit (workflow handles automatically)\n\n#### SVGs Don't Display in Profile\n\n**Problem**: Embedded images show broken or don't load\n\n**Solutions**:\n\n1. Verify URLs use your correct username\n2. Check files exist in `output/` directory\n3. Ensure branch name is correct (usually `main`)\n4. Try accessing the raw image URL directly\n5. Clear browser cache and refresh\n\nExample correct URL:\n\n```markdown\n![GitHub Stats](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/overview.svg)\n```\n\n#### Rate Limiting Issues\n\n**Problem**: Getting rate limit errors from GitHub API\n\n**Solutions**:\n\n- Workflow automatically handles with caching and retries\n- For local development, wait for rate limit reset\n- Use authenticated requests (GITHUB_TOKEN is recommended)\n- Enable caching in configuration\n\n#### AI Summaries Not Generating\n\n**Problem**: Repository analysis runs but summaries are missing\n\n**Solutions**:\n\n1. Verify `ANTHROPIC_API_KEY` is set correctly\n2. Check API key has sufficient credits/quota\n3. Review logs for API errors\n4. Try `--no-ai` flag to use README extraction fallback\n\n#### Local CLI Issues\n\n**Problem**: Commands fail or produce errors\n\n**Solutions**:\n\n1. Verify Python 3.11+ is installed: `python --version`\n2. Install dependencies: `pip install -r requirements.txt`\n3. Set environment variables correctly\n4. Run with `--verbose` flag for detailed output\n5. Check configuration with `spark config --validate`\n\n### Getting Help\n\nStill stuck? We're here to help:\n\n- \ud83d\udcd6 Check [Getting Started Guide](documentation/guides/getting-started.md) for detailed setup\n- \ud83d\udd0d Search [existing issues](https://github.com/markhazleton/github-stats-spark/issues)\n- \ud83d\udcac Start a [discussion](https://github.com/markhazleton/github-stats-spark/discussions)\n- \ud83d\udc1b [Open a new issue](https://github.com/markhazleton/github-stats-spark/issues/new) with details\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions of all kinds! Stats Spark is an open-source project that thrives on community involvement.\n\n### Ways to Contribute\n\n#### \ud83d\udc1b Report Bugs\n\nFound an issue? [Open a bug report](https://github.com/markhazleton/github-stats-spark/issues/new?labels=bug) with:\n\n- Clear description of the problem\n- Steps to reproduce\n- Expected vs. actual behavior\n- Environment details (Python version, OS, etc.)\n\n#### \ud83d\udca1 Suggest Features\n\nHave an idea? [Start a discussion](https://github.com/markhazleton/github-stats-spark/discussions) or [open a feature request](https://github.com/markhazleton/github-stats-spark/issues/new?labels=enhancement) describing:\n\n- The problem you're trying to solve\n- Proposed solution or feature\n- Use cases and benefits\n- Any relevant examples or mockups\n\n#### \ud83d\udd27 Submit Pull Requests\n\nReady to code? We'd love your contributions:\n\n1. **Fork the repository** and create a feature branch\n2. **Make your changes** following our code style\n3. **Add tests** for new functionality\n4. **Update documentation** as needed\n5. **Submit a PR** with a clear description\n\n**Good First Issues**: Look for issues labeled [`good first issue`](https://github.com/markhazleton/github-stats-spark/labels/good%20first%20issue) for beginner-friendly tasks.\n\n#### \ud83d\udcd6 Improve Documentation\n\n- Fix typos or clarify existing docs\n- Add examples or tutorials\n- Improve code comments\n- Create guides for common use cases\n\n#### \ud83c\udfa8 Share Your Usage\n\n- Show how you're using Stats Spark\n- Share your custom themes\n- Write blog posts or tutorials\n- Spread the word on social media\n\n### Development Setup\n\n```bash\n# Clone your fork\ngit clone https://github.com/YOUR_USERNAME/github-stats-spark.git\ncd github-stats-spark\n\n# Install development dependencies\npip install -r requirements-dev.txt\n\n# Run tests\npytest\n\n# Run tests with coverage\npytest --cov=spark --cov-report=html\n\n# View coverage report\nstart htmlcov/index.html  # Windows\nopen htmlcov/index.html   # macOS\nxdg-open htmlcov/index.html  # Linux\n```\n\n### Code Quality Standards\n\n- \u2705 Follow PEP 8 style guidelines\n- \u2705 Write descriptive commit messages\n- \u2705 Add docstrings to public functions/classes\n- \u2705 Include type hints where appropriate\n- \u2705 Maintain or improve test coverage (current: 52%, core: 80%+)\n- \u2705 Update relevant documentation\n\n### Architecture Overview\n\nFor contributors, see [API Reference](documentation/api/api-reference.md) for detailed module documentation including:\n\n- Core modules: `fetcher`, `calculator`, `visualizer`, `summarizer`\n- Analysis modules: `ranker`, `report_generator`, `unified_report_workflow`\n- Utilities: `cache`, `config`, `logger`\n\n## \ud83e\uddea Testing\n\nStats Spark maintains comprehensive test coverage to ensure reliability and quality.\n\n### Running Tests\n\n```bash\n# Run all tests\npytest\n\n# Run with detailed output\npytest -v\n\n# Run specific test file\npytest tests/unit/test_calculator.py\n\n# Run tests matching pattern\npytest -k \"test_spark_score\"\n\n# Run with coverage report\npytest --cov=spark --cov-report=html\n\n# View coverage in browser\nstart htmlcov/index.html  # Windows\nopen htmlcov/index.html   # macOS\n```\n\n### Coverage Statistics\n\n| Module | Coverage | Status |\n|--------|----------|--------|\n| **calculator.py** | 92% | \u2705 Excellent |\n| **fetcher.py** | 85% | \u2705 Excellent |\n| **cache.py** | 80% | \u2705 Good |\n| **visualizer.py** | 78% | \u2705 Good |\n| **ranker.py** | 75% | \u2705 Good |\n| **Overall** | 52% | \ud83d\udd36 Improving |\n\n**Target**: 80%+ coverage for all core modules\n\n### Test Organization\n\n```\ntests/\n\u251c\u2500\u2500 unit/              # Unit tests for individual modules\n\u2502   \u251c\u2500\u2500 test_calculator.py\n\u2502   \u251c\u2500\u2500 test_fetcher.py\n\u2502   \u251c\u2500\u2500 test_ranker.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 integration/       # Integration tests\n\u2502   \u251c\u2500\u2500 test_cli_analyze.py\n\u2502   \u251c\u2500\u2500 test_end_to_end.py\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 fixtures/          # Test data and configurations\n    \u251c\u2500\u2500 sample_config.yml\n    \u251c\u2500\u2500 sample_repositories.json\n    \u2514\u2500\u2500 ...\n```\n\n## \ud83d\udcc4 License\n\nMIT License - See [LICENSE](LICENSE) for details\n\nThis project is free and open-source. You can:\n\n- \u2705 Use commercially\n- \u2705 Modify and distribute\n- \u2705 Use privately\n- \u2705 Sublicense\n\nAttribution appreciated but not required!\n\n## \ud83d\ude4f Acknowledgments\n\nStats Spark is built on the shoulders of giants:\n\n### Core Technologies\n\n- **[PyGithub](https://github.com/PyGithub/PyGithub)** - GitHub API wrapper for Python\n- **[svgwrite](https://github.com/mozman/svgwrite)** - SVG generation library\n- **[Anthropic Claude](https://www.anthropic.com/)** - AI-powered repository summaries\n- **[Python 3.11+](https://www.python.org/)** - Modern Python features and performance\n\n### Inspiration\n\n- GitHub's contribution graph and profile statistics\n- Open source community for continuous feedback and ideas\n\n### Contributors\n\nThank you to all contributors who have helped make Stats Spark better!\n\n[View all contributors \u2192](https://github.com/markhazleton/github-stats-spark/graphs/contributors)\n\n## \ud83c\udf1f Star History\n\nIf you find Stats Spark useful, please consider giving it a star! \u2b50\n\nIt helps others discover the project and motivates continued development.\n\n[![Star History Chart](https://api.star-history.com/svg?repos=markhazleton/github-stats-spark&type=Date)](https://star-history.com/#markhazleton/github-stats-spark&Date)\n\n## \ud83d\udcca Usage Examples\n\n### In Profile README\n\n```markdown\n# Your Name\n\n![GitHub Stats](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/overview.svg)\n\n## Activity\n\n![Commit Heatmap](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/heatmap.svg)\n\n## Languages\n\n![Language Distribution](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/languages.svg)\n\n## Analysis\n\nCheck out my [detailed GitHub analysis](output/reports/YOUR_USERNAME-analysis.md) with AI-powered insights!\n```\n\n### In Project README\n\n```markdown\n## Developer Activity\n\n![GitHub Stats](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/overview.svg)\n\n*Updated daily via [Stats Spark](https://github.com/markhazleton/github-stats-spark)*\n```\n\n### Custom Sections\n\nCreate themed sections in your profile:\n\n```markdown\n<div align=\"center\">\n\n# \u26a1 GitHub Activity Dashboard\n\n![Overview](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/overview.svg)\n\n![Languages](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/languages.svg)\n![Streaks](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/streaks.svg)\n\n![Fun Stats](https://raw.githubusercontent.com/YOUR_USERNAME/github-stats-spark/main/output/fun.svg)\n\n</div>\n```\n\n---\n\n<div align=\"center\">\n\n## \u26a1 Powered by Stats Spark\n\n**Illuminate your GitHub activity with beautiful statistics and AI-powered insights**\n\n[![Get Started](https://img.shields.io/badge/Get%20Started-Quick%20Setup-blue?style=for-the-badge)](#-quick-start)\n[![View Sample](https://img.shields.io/badge/View%20Sample-Analysis%20Report-green?style=for-the-badge)](output/reports/markhazleton-analysis.md)\n[![Documentation](https://img.shields.io/badge/Read-Documentation-orange?style=for-the-badge)](documentation/README.md)\n\n[Quick Start](#-quick-start) \u2022 [Features](#-features) \u2022 [Documentation](documentation/README.md) \u2022 [Report Issue](https://github.com/markhazleton/github-stats-spark/issues) \u2022 [Contribute](#-contributing)\n\nMade with \u2764\ufe0f by developers, for developers\n\n</div>\n",
  "hash": "76552be34bfe4b512be605b639717f0179e927563b5485d5498ebd132c957971",
  "metadata": {
    "repository": {
      "owner": "markhazleton",
      "name": "github-stats-spark"
    },
    "category": "readme",
    "pushed_at": "2026-01-19T05:08:03+00:00",
    "ttl_enforced": false
  },
  "category": "readme",
  "owner": "markhazleton",
  "repo": "github-stats-spark",
  "week": "2026-01-19T05-08-03+00-00"
}