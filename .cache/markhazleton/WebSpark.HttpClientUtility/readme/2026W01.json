{
  "timestamp": "2026-01-04T22:53:11.545951+00:00",
  "value": "# WebSpark.HttpClientUtility\n\n**Drop-in HttpClient wrapper with Polly resilience, response caching, and OpenTelemetry for .NET 8-10+ APIs\u2014configured in one line**\n\n[![NuGet Version](https://img.shields.io/nuget/v/WebSpark.HttpClientUtility.svg)](https://www.nuget.org/packages/WebSpark.HttpClientUtility/)\n[![NuGet Downloads](https://img.shields.io/nuget/dt/WebSpark.HttpClientUtility.svg)](https://www.nuget.org/packages/WebSpark.HttpClientUtility/)\n[![Crawler Package](https://img.shields.io/nuget/v/WebSpark.HttpClientUtility.Crawler.svg?label=Crawler)](https://www.nuget.org/packages/WebSpark.HttpClientUtility.Crawler/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Build Status](https://github.com/MarkHazleton/HttpClientUtility/actions/workflows/publish-nuget.yml/badge.svg)](https://github.com/MarkHazleton/HttpClientUtility/actions/workflows/publish-nuget.yml)\n[![.NET 8-10](https://img.shields.io/badge/.NET-8--10-512BD4.svg)](https://dotnet.microsoft.com/download/dotnet)\n[![Documentation](https://img.shields.io/badge/docs-GitHub%20Pages-blue)](https://markhazleton.github.io/WebSpark.HttpClientUtility/)\n\n---\n\nStop writing 50+ lines of HttpClient setup. Get enterprise-grade resilience (retries, circuit breakers), intelligent caching, structured logging with correlation IDs, and OpenTelemetry tracing in a single `AddHttpClientUtility()` call. Perfect for microservices, background workers, and web scrapers.\n\n---\n\n## \ud83d\ude80 Why Choose WebSpark.HttpClientUtility?\n\n**Your HTTP setup in 1 line vs. 50+**\n\n| Feature | WebSpark.HttpClientUtility | Raw HttpClient | RestSharp | Refit |\n|---------|---------------------------|----------------|-----------|-------|\n| Setup Complexity | \u2b50 One line | \u2b50\u2b50\u2b50 50+ lines manual | \u2b50\u2b50 Low | \u2b50\u2b50 Low |\n| Built-in Retry/Circuit Breaker | \u2705 Polly integrated | \u274c Manual Polly setup | \u274c Manual | \u274c Manual |\n| Response Caching | \u2705 Configurable, in-memory | \u274c Manual | \u274c Manual | \u274c Manual |\n| Correlation IDs | \u2705 Automatic | \u274c Manual middleware | \u274c Manual | \u274c Manual |\n| OpenTelemetry | \u2705 Built-in | \u274c Manual ActivitySource | \u274c Manual | \u274c Manual |\n| Structured Logging | \u2705 Rich context | \u274c Manual ILogger | \u2b50\u2b50 Basic | \u2b50\u2b50 Basic |\n| Web Crawling | \u2705 Separate package | \u274c No | \u274c No | \u274c No |\n| Production Trust | \u2705 252+ tests, LTS support | \u2705 Microsoft-backed | \u2705 Popular (7M+ downloads) | \u2705 Popular (10M+ downloads) |\n\n**When to use WebSpark:**\n\n- \u2705 Building microservices with distributed tracing requirements\n- \u2705 Need resilience patterns without writing Polly boilerplate\n- \u2705 Want intelligent caching for API rate-limit compliance\n- \u2705 Building web scrapers or crawlers (with Crawler package)\n\n**When NOT to use WebSpark:**\n\n- \u274c You need declarative, type-safe API clients (use Refit)\n- \u274c You want maximum control and minimal magic (use raw HttpClient)\n- \u274c Legacy .NET Framework 4.x projects (WebSpark requires .NET 8+)\n\n---\n\n## \ud83d\udee1\ufe0f Production Trust\n\n**Battle-Tested & Production-Ready**\n\n- \u2705 **237+ unit tests** (711 test runs across 3 frameworks) with 100% passing - tested on .NET 8, 9, and 10\n- \u2705 **Source Link enabled** - step-through debugging with symbol packages (.snupkg)\n- \u2705 **Trimming & AOT ready** - annotated for Native AOT and IL trimming compatibility\n- \u2705 **Package validation** - baseline validation ensures no breaking changes\n- \u2705 **Zero-warning builds** - strict code quality with `TreatWarningsAsErrors=true`\n- \u2705 **Continuous Integration** via GitHub Actions - every commit tested\n- \u2705 **Semantic Versioning** - predictable, safe upgrades\n- \u2705 **Zero breaking changes** within major versions - backward compatibility guaranteed\n- \u2705 **Framework Support:** .NET 8 LTS (supported until Nov 2026), .NET 9, .NET 10 (Preview)\n- \u2705 **MIT Licensed** - free for commercial use\n\n**Support & Maintenance**\n\n- \ud83d\udd04 **Active development** - regular updates and improvements\n- \ud83d\udcc5 **Long-term support** - each major version supported for 18+ months\n- \ud83d\udcac **Community support** - GitHub Discussions for questions and best practices\n- \ud83d\udcd6 **Comprehensive documentation** - [Full docs site](https://markhazleton.github.io/WebSpark.HttpClientUtility/)\n\n**Breaking Change Commitment**\n\nWe follow semantic versioning strictly:\n\n- **Patch versions (2.0.x):** Bug fixes only, zero breaking changes\n- **Minor versions (2.x.0):** New features, backward compatible\n- **Major versions (x.0.0):** Breaking changes with detailed migration guides\n\n---\n\n## \ud83d\udce6 v2.0 - Now in Two Focused Packages!\n\nStarting with v2.0, the library is split into two packages:\n\n| Package | Purpose | Size | Use When |\n|---------|---------|------|----------|\n| **[WebSpark.HttpClientUtility](https://www.nuget.org/packages/WebSpark.HttpClientUtility/)** | Core HTTP features | 163 KB | You need HTTP client utilities (authentication, caching, resilience, telemetry) |\n| **[WebSpark.HttpClientUtility.Crawler](https://www.nuget.org/packages/WebSpark.HttpClientUtility.Crawler/)** | Web crawling extension | 75 KB | You need web crawling, robots.txt parsing, sitemap generation |\n\n**Upgrading from v1.x?** Most users need no code changes! See [Migration Guide](#-upgrading-from-v1x).\n\n## \ud83d\udcda Documentation\n\n**[View Full Documentation \u2192](https://markhazleton.github.io/WebSpark.HttpClientUtility/)**\n\nThe complete documentation site includes:\n- Getting started guide\n- Feature documentation\n- API reference\n- Code examples\n- Best practices\n\n## \u26a1 30-Second Quick Start\n\n**Install**\n\n```bash\ndotnet add package WebSpark.HttpClientUtility\n```\n\n**Minimal Example (Absolute Minimum)**\n\n```csharp\n// Program.cs\nvar builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddHttpClientUtility();\nvar app = builder.Build();\n\napp.MapGet(\"/weather\", async (IHttpRequestResultService http) =>\n{\n    var request = new HttpRequestResult<WeatherData>\n    {\n        RequestPath = \"https://api.weather.com/forecast?city=Seattle\",\n        RequestMethod = HttpMethod.Get\n    };\n    var result = await http.HttpSendRequestResultAsync(request);\n    return result.IsSuccessStatusCode ? Results.Ok(result.ResponseResults) : Results.Problem();\n});\n\napp.Run();\n\nrecord WeatherData(string City, int Temp);\n```\n\nThat's it! You now have:\n\n- \u2705 Automatic correlation IDs for tracing\n- \u2705 Structured logging with request/response details\n- \u2705 Request timing telemetry\n- \u2705 Proper error handling and exception management\n- \u2705 Support for .NET 8 LTS, .NET 9, and .NET 10 (Preview)\n\n<details>\n<summary>\ud83d\udcd6 Show more: Service-based pattern with error handling</summary>\n\n```csharp\n// Program.cs\nbuilder.Services.AddHttpClientUtility(options =>\n{\n    options.EnableCaching = true;      // Cache responses\n    options.EnableResilience = true;   // Retry on failure\n});\n\n// WeatherService.cs\npublic class WeatherService\n{\n    private readonly IHttpRequestResultService _http;\n    private readonly ILogger<WeatherService> _logger;\n\n    public WeatherService(\n        IHttpRequestResultService http,\n        ILogger<WeatherService> logger)\n    {\n        _http = http;\n        _logger = logger;\n    }\n\n    public async Task<WeatherData?> GetWeatherAsync(string city)\n    {\n        var request = new HttpRequestResult<WeatherData>\n        {\n            RequestPath = $\"https://api.weather.com/forecast?city={city}\",\n            RequestMethod = HttpMethod.Get,\n            CacheDurationMinutes = 10  // Cache for 10 minutes\n        };\n\n        var result = await _http.HttpSendRequestResultAsync(request);\n\n        if (!result.IsSuccessStatusCode)\n        {\n            _logger.LogError(\n                \"Weather API failed: {StatusCode} - {Error}\",\n                result.StatusCode,\n                result.ErrorDetails\n            );\n            return null;\n        }\n\n        return result.ResponseResults;\n    }\n}\n```\n\n</details>\n\n<details>\n<summary>\ud83d\udcd6 Show more: Full-featured with auth and observability</summary>\n\n```csharp\n// Program.cs - Advanced configuration\nbuilder.Services.AddHttpClientUtility(options =>\n{\n    options.EnableCaching = true;\n    options.EnableResilience = true;\n    options.ResilienceOptions.MaxRetryAttempts = 3;\n    options.ResilienceOptions.RetryDelay = TimeSpan.FromSeconds(2);\n    options.DefaultTimeout = TimeSpan.FromSeconds(30);\n});\n\n// WeatherService.cs - Advanced usage\npublic async Task<WeatherData?> GetWeatherWithAuthAsync(string city, string apiKey)\n{\n    var request = new HttpRequestResult<WeatherData>\n    {\n        RequestPath = $\"https://api.weather.com/forecast?city={city}\",\n        RequestMethod = HttpMethod.Get,\n        CacheDurationMinutes = 10,\n        Headers = new Dictionary<string, string>\n        {\n            [\"X-API-Key\"] = apiKey,\n            [\"Accept\"] = \"application/json\"\n        }\n    };\n\n    var result = await _http.HttpSendRequestResultAsync(request);\n\n    // Correlation ID is automatically logged and propagated\n    _logger.LogInformation(\n        \"Weather request completed in {Duration}ms with correlation {CorrelationId}\",\n        result.RequestDuration,\n        result.CorrelationId\n    );\n\n    return result.IsSuccessStatusCode ? result.ResponseResults : null;\n}\n```\n\n</details>\n\n### Web Crawling Features (Crawler Package)\n\n**Install Both Packages**\n```bash\ndotnet add package WebSpark.HttpClientUtility\ndotnet add package WebSpark.HttpClientUtility.Crawler\n```\n\n**Register Services**\n```csharp\n// Program.cs\nbuilder.Services.AddHttpClientUtility();\nbuilder.Services.AddHttpClientCrawler();  // Adds crawler features\n```\n\n**Use Crawler**\n```csharp\npublic class SiteAnalyzer\n{\n    private readonly ISiteCrawler _crawler;\n    \n    public SiteAnalyzer(ISiteCrawler crawler) => _crawler = crawler;\n\n    public async Task<CrawlResult> AnalyzeSiteAsync(string url)\n    {\n        var options = new CrawlerOptions\n        {\n            MaxDepth = 3,\n            MaxPages = 100,\n            RespectRobotsTxt = true\n        };\n        \n        return await _crawler.CrawlAsync(url, options);\n    }\n}\n```\n\n## \ud83d\ude80 Features\n\n### Base Package Features\n- **Simple API** - Intuitive request/response model\n- **Authentication** - Bearer token, Basic auth, API key providers\n- **Correlation IDs** - Automatic tracking across distributed systems\n- **Structured Logging** - Rich context in all log messages\n- **Telemetry** - Request timing and performance metrics\n- **Error Handling** - Standardized exception processing\n- **Type-Safe** - Strongly-typed request and response models\n- **Caching** - In-memory response caching (optional)\n- **Resilience** - Polly retry and circuit breaker policies (optional)\n- **Concurrent Requests** - Parallel request processing\n- **Fire-and-Forget** - Background request execution\n- **Streaming** - Efficient handling of large responses\n- **OpenTelemetry** - Full observability integration (optional)\n- **CURL Export** - Generate CURL commands for debugging\n- **Source Link** - Step-through debugging with symbol packages\n- **Trimming/AOT Ready** - Compatible with Native AOT and IL trimming\n- **Package Validation** - Baseline validation ensures stability\n\n### Crawler Package Features\n- **Site Crawling** - Full website crawling with depth control\n- **Robots.txt** - Automatic compliance with robots.txt rules\n- **Sitemap Generation** - Create XML sitemaps from crawl results\n- **HTML Parsing** - Extract links and metadata with HtmlAgilityPack\n- **SignalR Progress** - Real-time crawl progress updates\n- **CSV Export** - Export crawl results to CSV files\n- **Performance Tracking** - Monitor crawl speed and efficiency\n\n## \ud83d\udcda Common Scenarios\n\n### Enable Caching\n```csharp\nbuilder.Services.AddHttpClientUtility(options =>\n{\n    options.EnableCaching = true;\n});\n\n// In your service\nvar request = new HttpRequestResult<Product>\n{\n    RequestPath = \"https://api.example.com/products/123\",\n    RequestMethod = HttpMethod.Get,\n    CacheDurationMinutes = 10  // Cache for 10 minutes\n};\n```\n\n### Add Resilience (Retry + Circuit Breaker)\n```csharp\nbuilder.Services.AddHttpClientUtility(options =>\n{\n    options.EnableResilience = true;\n  options.ResilienceOptions.MaxRetryAttempts = 3;\n    options.ResilienceOptions.RetryDelay = TimeSpan.FromSeconds(2);\n});\n```\n\n### All Features Enabled\n```csharp\nbuilder.Services.AddHttpClientUtilityWithAllFeatures();\n```\n\n## \ud83d\udd04 Upgrading from v1.x\n\n### If You DON'T Use Web Crawling\n\n**No code changes required!** Simply upgrade:\n\n```bash\ndotnet add package WebSpark.HttpClientUtility --version 2.0.0\n```\n\nYour existing code continues to work exactly as before. All core HTTP features (authentication, caching, resilience, telemetry, etc.) are still in the base package with the same API.\n\n### If You DO Use Web Crawling\n\nThree simple steps to migrate:\n\n**Step 1**: Install the crawler package\n```bash\ndotnet add package WebSpark.HttpClientUtility.Crawler --version 2.0.0\n```\n\n**Step 2**: Add using directive\n```csharp\nusing WebSpark.HttpClientUtility.Crawler;\n```\n\n**Step 3**: Update service registration\n```csharp\n// v1.x (old)\nservices.AddHttpClientUtility();\n\n// v2.0 (new)\nservices.AddHttpClientUtility();\nservices.AddHttpClientCrawler();  // Add this line\n```\n\nThat's it! Your crawler code (ISiteCrawler, SiteCrawler, SimpleSiteCrawler, etc.) works identically after these changes.\n\n**Need Help?** See the [detailed migration guide](https://markhazleton.github.io/WebSpark.HttpClientUtility/getting-started/migration-v2/) or [open an issue](https://github.com/MarkHazleton/HttpClientUtility/issues).\n\n## \ud83d\udcd6 Documentation\n\n- **[Getting Started Guide](documentation/GettingStarted.md)** - Complete walkthrough\n- **[Configuration Options](documentation/Configuration.md)** - All settings explained\n- **[Caching Guide](documentation/Caching.md)** - Response caching strategies\n- **[Resilience Guide](documentation/Resilience.md)** - Retry and circuit breaker patterns\n- **[Web Crawling](documentation/WebCrawling.md)** - Site crawler features\n- **[Migration Guide](documentation/Migration.md)** - From raw HttpClient\n- **[API Reference](documentation/ApiReference.md)** - Complete API documentation\n\n## \ud83c\udf93 Sample Projects\n\nExplore working examples in the [samples directory](samples/):\n- **BasicUsage** - Simple GET/POST requests\n- **WithCaching** - Response caching implementation\n- **WithResilience** - Retry and circuit breaker patterns\n- **ConcurrentRequests** - Parallel request processing\n- **WebCrawler** - Site crawling example\n\n## \ud83e\udd1d Contributing\n\nContributions are welcome! See our [Contributing Guide](documentation/CONTRIBUTING.md) for details.\n\n1. Fork the repository\n2. Create a feature branch\n3. Add tests for your changes\n4. Ensure all tests pass\n5. Submit a pull request\n\n## \ud83d\udcca Project Stats\n\n- **252+ Unit Tests** - 100% passing\n- **Supports .NET 8 LTS, .NET 9, & .NET 10 (Preview)**\n- **MIT Licensed** - Free for commercial use\n- **Active Maintenance** - Regular updates\n\n## \ud83d\udce6 Related Packages\n\n| Package | Purpose | Status |\n|---------|---------|--------|\n| [WebSpark.HttpClientUtility.Testing](https://nuget.org/packages/WebSpark.HttpClientUtility.Testing) | Test helpers & fakes for unit testing | \u2705 Available (v2.1.0+) |\n\n**Testing Package Features:**\n\n- **FakeHttpResponseHandler** - Mock HTTP responses without network calls\n- **Fluent API** - Easy test setup with `ForRequest().RespondWith()`\n- **Sequential Responses** - Test retry behavior with multiple responses\n- **Request Verification** - Assert requests were made correctly\n- **Latency Simulation** - Test timeout scenarios\n\n```bash\ndotnet add package WebSpark.HttpClientUtility.Testing\n```\n\nSee the [Testing documentation](https://markhazleton.github.io/WebSpark.HttpClientUtility/testing/) for examples.\n\n## \ud83d\udcc4 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## \ud83d\udd17 Links\n\n- [GitHub Repository](https://github.com/markhazleton/httpclientutility)\n- [NuGet Package](https://www.nuget.org/packages/WebSpark.HttpClientUtility)\n- [Changelog](CHANGELOG.md)\n- [Issue Tracker](https://github.com/markhazleton/httpclientutility/issues)\n- [Discussions](https://github.com/markhazleton/httpclientutility/discussions)\n\n---\n\n**Questions or Issues?** [Open an issue](https://github.com/markhazleton/httpclientutility/issues) or [start a discussion](https://github.com/markhazleton/httpclientutility/discussions)!\n",
  "hash": "28090dc729ba993bcb7a4a4c83efaf6db76a6bad9799e279c2de154b9e7d5720",
  "metadata": {
    "repository": {
      "owner": "markhazleton",
      "name": "WebSpark.HttpClientUtility"
    },
    "category": "readme",
    "pushed_at": "2026-01-04T19:06:38+00:00",
    "ttl_enforced": false
  },
  "category": "readme",
  "owner": "markhazleton",
  "repo": "WebSpark.HttpClientUtility",
  "week": "2026W01"
}