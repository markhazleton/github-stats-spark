{
  "timestamp": "2026-01-31T15:53:52.582952+00:00",
  "value": "# MuseumSpark \ud83c\udfdb\ufe0f\n\n> **The strategic travel planner for art lovers.**  \n> Curate, prioritize, and optimize your museum visits across North America.\n\n![Status](https://img.shields.io/badge/Status-Active_Development-brightgreen)\n![Phase](https://img.shields.io/badge/Phase-1_Data_Enrichment-blue)\n![License](https://img.shields.io/badge/License-MIT-green)\n![Dataset](https://img.shields.io/badge/Museums-1,269_Tracked-purple)\n![Data Quality](https://img.shields.io/badge/Enriched-0.08%25-orange)\n\n---\n\n## \ud83c\udfa8 About MuseumSpark\n\n**MuseumSpark** transforms the [Walker Art Center Reciprocal Program](https://walkerart.org/support/membership/reciprocal-membership/) membership list into an intelligent, data-rich travel planning resource for art enthusiasts.\n\n### The Vision\n\nRather than a simple directory, MuseumSpark provides:\n\n- **Priority Scoring**: Rank museums by artistic strength (Impressionist & Modern/Contemporary collections), historical context, and reputation\n- **Smart Travel Planning**: City tier classification, visit duration estimates, and nearby museum clustering\n- **Data Enrichment**: Multi-source pipeline combining Wikidata, Wikipedia, museum websites, and structured data extraction\n- **Personalized Experience**: (Coming Phase 4) Save favorites, track visits, generate custom itineraries with AI assistance\n\nWhether planning a 2-hour layover or a weekend art tour, MuseumSpark helps you discover the right museums for your interests and time constraints.\n\n---\n\n## \u2728 Current Features\n\n### \ud83d\udd0d Comprehensive Museum Browser\n- **1,269 museums** from the Walker Art Reciprocal Program\n- Browse by state/province, search by name, filter by attributes\n- Detailed museum pages with contact info, hours, and enrichment data\n\n### \ud83d\udcca Data Quality Dashboard\n- Real-time progress tracking of dataset enrichment\n- State-by-state completeness metrics\n- Transparency on data source and validation status\n\n### \ud83d\udee0\ufe0f Multi-Phase Enrichment Pipeline\n**Phase 0**: Identity verification (Wikidata, website validation)  \n**Phase 0.5**: Wikidata structured data extraction  \n**Phase 0.7**: Official website metadata harvesting  \n**Phase 1**: Backbone data (address, city tier, museum type)  \n**Phase 1.5**: Wikipedia article extraction  \n**Phase 1.75**: Heuristic fallback for missing data  \n**Phase 1.8**: CSV lookup integration  \n**Phase 1.9**: Museum planner metadata (product owner scores & notes)  \n**Phase 2**: Expert scoring (collections, historical context)  \n**Phase 2.5**: Rich content extraction  \n**Phase 3**: Priority score calculation\n\n### \ud83d\udd10 Data Quality Assurance\n- JSON Schema validation for all museum records\n- Automated quality checks and evidence tracking\n- \"Never Replace Known With Null\" data quality rule enforcement\n\n---\n\n## \ud83d\uddfa\ufe0f Development Roadmap\n\n### \u2705 Phase 0\u20131: Data Foundation (Current Phase \u2014 80% Complete)\n**Status**: Active development  \n**Progress**: 1 of 1,269 museums fully enriched (0.08%)\n\n**Completed**:\n- \u2705 React + Vite static site with browse/search/filter functionality\n- \u2705 Museum detail pages with state file drill-down\n- \u2705 Progress dashboard tracking enrichment status\n- \u2705 JSON Schema validation pipeline\n- \u2705 Multi-phase data enrichment architecture\n- \u2705 Wikidata, Wikipedia, and website scraping infrastructure\n- \u2705 Walker Art Reciprocal roster ingestion and indexing\n\n**In Progress**:\n- \ud83d\udd04 Dataset enrichment (continuing Phase 0\u20131.8 pipeline runs)\n- \ud83d\udd04 GitHub Pages deployment configuration\n\n**Next Steps**:\n- Scale enrichment runs to complete remaining 1,268 museums\n- Implement caching strategies for external API calls\n- Begin Phase 2 scoring for art-focused museums\n\n---\n\n### \ud83e\udde0 Phase 2: Expert Scoring (Planned Q2 2026)\n**Goal**: Assign priority scores to art museums based on collection strength\n\n**Key Activities**:\n- Define scoring rubric for Impressionist and Modern/Contemporary collections\n- Expert review of major museums (Tier 1 cities first)\n- Historical context quality assessment\n- Reputation and collection tier classification\n\n---\n\n### \ud83e\udd16 Phase 2.5\u20133: AI-Assisted Content & Validation (Planned Q3 2026)\n**Goal**: Leverage LLMs for deeper museum analysis\n\n**Approach**:\n- Claude/OpenAI agents to analyze museum websites for collection depth\n- Automated extraction of signature artists, special exhibitions\n- Quality validation and expert auditing of AI-generated scores\n\n---\n\n### \ud83d\ude80 Phase 4: Interactive Platform (Planned Q4 2026)\n**Goal**: Full-featured travel companion with personalization\n\n**Features**:\n- FastAPI backend with user authentication\n- Save favorites and track visited museums\n- Trip planning and itinerary generation\n- AI travel agent for personalized recommendations\n- SQLite persistence for user data\n\n---\n\n## \ud83d\udee0\ufe0f Technology Stack\n\n### Frontend\n- **React 19** - Modern UI library\n- **Vite 7** - Lightning-fast build tool\n- **Tailwind CSS 4** - Utility-first styling\n- **React Router 7** - Client-side routing\n\n### Data Pipeline\n- **Python 3.11+** - Core scripting language\n- **Pydantic 2** - Data validation and schema management\n- **JSON Schema** - Dataset validation framework\n- **BeautifulSoup4** - HTML parsing and web scraping\n- **html2text** - Clean markdown conversion for LLM input\n\n### Data Sources\n- **Wikidata** - Structured museum metadata\n- **Wikipedia** - Article content and cultural context\n- **Museum Websites** - Official hours, addresses, descriptions\n- **Walker Art Center** - Reciprocal membership roster\n\n### Future Backend (Phase 4)\n- **FastAPI** - Modern Python API framework\n- **SQLite** - Embedded database for user data\n- **PydanticAI** - Structured LLM interactions\n- **OpenAI/Anthropic** - AI-powered content generation\n\n### Deployment\n- **Phase 1**: GitHub Pages (static hosting)\n- **Phase 4**: Azure Windows Server VM (self-hosted)\n\n---\n\n## \ud83d\ude80 Getting Started\n\n### Prerequisites\n- **Node.js 18+** (for the website)\n- **Python 3.11+** (for data scripts)\n- **Git** (for version control)\n\n### Quick Start\n\n#### 1. Clone the Repository\n```bash\ngit clone https://github.com/markhazleton/MuseumSpark.git\ncd MuseumSpark\n```\n\n#### 2. Run the Website Locally\n```bash\ncd site\nnpm install\nnpm run dev\n```\nOpen [http://localhost:5173](http://localhost:5173) to view the app.\n\nThe site will automatically sync data from `data/` to `site/public/data/` on startup.\n\n#### 3. Work with Data Scripts (Optional)\n\n**Windows (PowerShell)**:\n```powershell\n# Create and activate virtual environment\npython -m venv .venv\n.\\.venv\\Scripts\\Activate.ps1\n\n# Install dependencies\npip install -r scripts\\requirements.txt\n\n# Validate dataset\npython scripts\\validation\\validate-json.py\n\n# Build indices\npython scripts\\builders\\build-index.py\npython scripts\\builders\\build-progress.py\n\n# Run enrichment pipeline\npython scripts\\pipeline\\run-complete-pipeline.py\n```\n\n**macOS/Linux**:\n```bash\n# Create and activate virtual environment\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# Install dependencies\npip install -r scripts/requirements.txt\n\n# Validate dataset\npython scripts/validation/validate-json.py\n\n# Build indices\npython scripts/builders/build-index.py\n```\n\n---\n\n## \ud83d\udcc2 Project Structure\n\n```\nMuseumSpark/\n\u251c\u2500\u2500 .github/              # GitHub configuration\n\u251c\u2500\u2500 data/                 # Museum dataset (single source of truth)\n\u2502   \u251c\u2500\u2500 archive/          # Historical data and old test runs\n\u2502   \u2502   \u251c\u2500\u2500 old_runs_20260116-20260117/  # Archived test runs\n\u2502   \u2502   \u2514\u2500\u2500 temp_files_archive/          # Archived temp files\n\u2502   \u251c\u2500\u2500 cache/            # Runtime caches (gitignored)\n\u2502   \u2502   \u251c\u2500\u2500 http/         # HTTP response cache\n\u2502   \u2502   \u251c\u2500\u2500 wikidata/     # Wikidata query cache\n\u2502   \u2502   \u251c\u2500\u2500 wikipedia_population/  # Wikipedia data cache\n\u2502   \u2502   \u251c\u2500\u2500 open-data/    # OpenStreetMap cache\n\u2502   \u2502   \u251c\u2500\u2500 phase0/       # Phase 0 enrichment cache\n\u2502   \u2502   \u2514\u2500\u2500 phase2/       # Phase 2 enrichment cache\n\u2502   \u251c\u2500\u2500 index/            # Generated indices for the app\n\u2502   \u2502   \u251c\u2500\u2500 all-museums.json         # Master museum list\n\u2502   \u2502   \u251c\u2500\u2500 all-museums-enriched.json  # Enriched master list\n\u2502   \u2502   \u251c\u2500\u2500 progress.json             # Enrichment progress\n\u2502   \u2502   \u251c\u2500\u2500 missing-report.json       # Data gap analysis\n\u2502   \u2502   \u251c\u2500\u2500 tour-planning-scores.json # Priority scores\n\u2502   \u2502   \u2514\u2500\u2500 walker-reciprocal.csv     # Original roster\n\u2502   \u251c\u2500\u2500 runs/             # Pipeline run outputs (gitignored)\n\u2502   \u251c\u2500\u2500 schema/           # JSON Schema definitions\n\u2502   \u2502   \u2514\u2500\u2500 museum.schema.json\n\u2502   \u2514\u2500\u2500 states/           # Per-state museum records (canonical)\n\u2502       \u251c\u2500\u2500 alabama.json\n\u2502       \u251c\u2500\u2500 alaska.json\n\u2502       \u2514\u2500\u2500 ... (58 states/provinces/territories)\n\u251c\u2500\u2500 Documentation/        # Architecture and requirements\n\u2502   \u251c\u2500\u2500 ApplicationArchitecture.md\n\u2502   \u251c\u2500\u2500 MasterRequirements.md\n\u2502   \u251c\u2500\u2500 DataEnrichmentStrategy.md\n\u2502   \u251c\u2500\u2500 MuseumAPI.md\n\u2502   \u2514\u2500\u2500 ... (20+ docs)\n\u251c\u2500\u2500 scripts/              # Python data pipeline\n\u2502   \u251c\u2500\u2500 builders/         # Index building scripts\n\u2502   \u251c\u2500\u2500 phases/           # Enrichment phase implementations\n\u2502   \u251c\u2500\u2500 pipeline/         # Pipeline orchestration\n\u2502   \u251c\u2500\u2500 validation/       # Data validation tools\n\u2502   \u251c\u2500\u2500 analyze_*.py      # Analysis scripts\n\u2502   \u2514\u2500\u2500 requirements.txt  # Python dependencies\n\u251c\u2500\u2500 site/                 # React frontend application\n\u2502   \u251c\u2500\u2500 public/           # Static assets\n\u2502   \u251c\u2500\u2500 scripts/          # Build scripts (data sync)\n\u2502   \u251c\u2500\u2500 src/              # React source code\n\u2502   \u2502   \u251c\u2500\u2500 components/   # UI components\n\u2502   \u2502   \u251c\u2500\u2500 pages/        # Route pages\n\u2502   \u2502   \u2514\u2500\u2500 App.jsx       # Main app component\n\u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2514\u2500\u2500 vite.config.ts\n\u251c\u2500\u2500 specs/                # Feature specifications\n\u2502   \u2514\u2500\u2500 001-museum-trip-planner/\n\u251c\u2500\u2500 CLEANUP.md            # Maintenance and cleanup guide\n\u251c\u2500\u2500 CLAUDE.md             # AI assistant context document\n\u251c\u2500\u2500 LICENSE               # MIT License\n\u2514\u2500\u2500 README.md             # This file\n```\n\n---\n\n## \ud83d\udcca Dataset Overview\n\n### Current Status (as of January 18, 2026)\n- **Total Museums**: 1,269\n- **Fully Enriched**: 1 (0.08%)\n- **Placeholder Records**: 1,268 (99.92%)\n\n### Geographic Coverage\nMuseums across **58 jurisdictions**:\n- **United States**: 50 states + DC + Puerto Rico\n- **Canada**: All provinces and territories\n- **International**: Bermuda, Mexico\n\n### Data Quality Levels\n- **FULL**: Complete enrichment with all required fields validated\n- **PLACEHOLDER**: Basic name/state only; awaiting enrichment\n\n### Enrichment Pipeline Phases\nEach museum progresses through 10+ enrichment phases:\n- **Phase 0**: Identity & website validation\n- **Phase 0.5**: Wikidata integration\n- **Phase 0.7**: Website metadata extraction\n- **Phase 1**: Address, city tier, museum type\n- **Phase 1.5**: Wikipedia article content\n- **Phase 1.75**: Heuristic fallback for missing data\n- **Phase 1.8**: CSV reference lookup\n- **Phase 2**: Collection scoring (art museums only)\n- **Phase 2.5**: Rich content extraction\n- **Phase 3**: Priority score calculation\n\n---\n\n## \ud83e\uddea Data Quality & Validation\n\n### Validation Framework\n- **JSON Schema**: Structural validation for all museum records\n- **Pydantic Models**: Runtime validation with type safety\n- **Evidence Tracking**: Provenance metadata for all enriched fields\n- **Quality Rules**: \"Never Replace Known With Null\" guardrail\n\n### Key Validation Scripts\n```bash\n# Validate all museum records against schema\npython scripts/validation/validate-json.py\n\n# Check cache consistency with state files\npython scripts/validate_cache_vs_state.py\n\n# Analyze missing data gaps\npython scripts/analyze_missing.py\n\n# Review Wikipedia coverage\npython scripts/check_wikipedia_coverage.py\n\n# Generate Phase 2 validation report\npython scripts/phase2_validation_report.py\n```\n\n### Quality Metrics\n- Schema compliance: 100% (all records pass JSON Schema)\n- Address completeness: Varies by state (tracked in progress.json)\n- Wikidata coverage: ~85% of museums have Wikidata IDs\n- Wikipedia articles: ~40% have associated articles\n\n---\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions from developers, data curators, and art enthusiasts!\n\n### Ways to Contribute\n- **Code**: Improve the website, add features, fix bugs\n- **Data**: Correct museum information, add missing details\n- **Documentation**: Clarify guides, add examples\n- **Testing**: Report bugs, suggest improvements\n\n### Getting Started\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature/your-feature`\n3. Make your changes and test thoroughly\n4. Commit with clear messages: `git commit -m \"Add feature X\"`\n5. Push and open a Pull Request\n\n### Data Corrections\nFound incorrect museum info? Please:\n1. Check the museum's official website for accurate data\n2. Open an issue with the correction and source URL\n3. Or submit a PR updating the relevant state JSON file\n\n---\n\n## \ud83d\udcc4 License\n\nDistributed under the **MIT License**. See [LICENSE](LICENSE) for details.\n\n### Data Attribution\n- **Walker Art Center**: Original reciprocal membership roster\n- **Wikidata**: CC0 (Public Domain)\n- **Wikipedia**: CC BY-SA 3.0\n- **Museum Websites**: Factual data extraction (fair use)\n\n---\n\n## \ud83d\ude4f Acknowledgments\n\n- **Walker Art Center** - For maintaining the reciprocal membership program\n- **Wikidata Community** - For comprehensive structured museum data\n- **Wikipedia Contributors** - For detailed cultural institution articles\n- **Open Source Community** - For the tools that make this possible\n\n---\n\n## \ud83d\udcde Support & Contact\n\n- **Issues**: [GitHub Issues](https://github.com/markhazleton/MuseumSpark/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/markhazleton/MuseumSpark/discussions)\n- **Documentation**: [Documentation folder](Documentation/)\n- **Project Updates**: Watch this repository for releases\n\n---\n\n## \ud83e\uddf9 Maintenance\n\nFor information on project cleanup, archiving old data, and maintaining a clean workspace:\n- See [CLEANUP.md](CLEANUP.md) for maintenance guidelines\n- Temp files and test runs are automatically gitignored\n- Archive directories preserve historical data without cluttering the workspace\n\n---\n\n*Built with \u2764\ufe0f for art lovers, by art lovers.*  \n*Empowering smarter museum travel, one enriched record at a time.*\n",
  "hash": "3c31b988368505c434dd3f9a8bbc8af550bea220d2e1ced9f85ca120909cd3e5",
  "metadata": {
    "repository": {
      "owner": "markhazleton",
      "name": "MuseumSpark"
    },
    "category": "readme",
    "pushed_at": "2026-01-31T05:26:03+00:00",
    "ttl_enforced": false
  },
  "category": "readme",
  "owner": "markhazleton",
  "repo": "MuseumSpark",
  "week": "2026-01-31T05-26-03+00-00"
}